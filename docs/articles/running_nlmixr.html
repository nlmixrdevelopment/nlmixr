<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Running PK models with nlmixr • nlmixr</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/flatly/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Running PK models with nlmixr">
<meta property="og:description" content="">
<meta property="og:image" content="/logo.png">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">nlmixr</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.1.0.8</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fas fa fas fa-book"></span>
     
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="divider">
    <li class="dropdown-header">Getting started</li>
    <li>
      <a href="../articles/running_nlmixr.html">Introduction to Running Nlmixr</a>
    </li>
    <li>
      <a href="../articles/multiple-endpoints.html">Using Multiple Endpoints in Nlmixr</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Going further</li>
    <li>
      <a href="../articles/modelPiping.html">Model Piping</a>
    </li>
    <li>
      <a href="../articles/broom.html">Sweeping models to tidy datasets (broom)</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fas fa fas fa-chalkboard-teacher"></span>
     
    Example models
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/addingCovariances.html">Phenobarbatol with correlations</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Page 2018</li>
    <li>
      <a href="https://nlmixrdevelopment.github.io/nlmixr.examples/articles/nimo.html">Nonlinear PK/PD -- Nimotuzumab</a>
    </li>
    <li>
      <a href="https://nlmixrdevelopment.github.io/nlmixr.examples/articles/mavoglurant.html">PBPK -- Mavoglurant</a>
    </li>
  </ul>
</li>
<li>
  <a href="https://github.com/nlmixrdevelopment/nlmixr/raw/master/CheatSheet_nlmixr.pdf">
    <span class="fa fa-scroll fa-lg"></span>
     
    Cheat Sheet
  </a>
</li>
<li>
  <a href="../reference/index.html">
    <span class="fa fa-file-code-o fa-lg"></span>
     
    Functions
  </a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/nlmixrdevelopment/nlmixr">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/nlmixrdevelopment/nlmixr/releases">
    <span class="fa fa-download"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Running PK models with nlmixr</h1>
            
            <h4 class="date">2019-05-10</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/nlmixrdevelopment/nlmixr/blob/master/vignettes/running_nlmixr.Rmd"><code>vignettes/running_nlmixr.Rmd</code></a></small>
      <div class="hidden name"><code>running_nlmixr.Rmd</code></div>

    </div>

    
    
<div class="figure">
<img src="logo.png" alt="nlmixr"><p class="caption">nlmixr</p>
</div>
<div id="running-pk-models-with-nlmixr" class="section level1">
<h1 class="hasAnchor">
<a href="#running-pk-models-with-nlmixr" class="anchor"></a>Running PK models with nlmixr</h1>
<p>nlmixr uses a unified interface for specifying and running models. Let’s start with a very simple PK example, using the single-dose theophylline dataset generously provided by Dr. Robert A. Upton of the University of California, San Francisco:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Load libraries
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(ggplot2)
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(nlmixr)

## To allow nlmixr to reload runs without large run times
## To run the actual models on your system, take the save options off.
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/options">options</a></span>(<span class="dt">nlmixr.save=</span><span class="ot">TRUE</span>,
        <span class="dt">nlmixr.save.dir=</span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/system.file">system.file</a></span>(<span class="dt">package=</span><span class="st">"nlmixr"</span>));


<span class="kw"><a href="https://www.rdocumentation.org/packages/utils/topics/str">str</a></span>(theo_sd)</code></pre></div>
<pre><code>## 'data.frame':    144 obs. of  7 variables:
##  $ ID  : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ TIME: num  0 0 0.25 0.57 1.12 2.02 3.82 5.1 7.03 9.05 ...
##  $ DV  : num  0 0.74 2.84 6.57 10.5 9.66 8.58 8.36 7.47 6.89 ...
##  $ AMT : num  320 0 0 0 0 ...
##  $ EVID: int  101 0 0 0 0 0 0 0 0 0 ...
##  $ CMT : int  1 2 2 2 2 2 2 2 2 2 ...
##  $ WT  : num  79.6 79.6 79.6 79.6 79.6 79.6 79.6 79.6 79.6 79.6 ...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/ggplot">ggplot</a></span>(theo_sd, <span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/aes">aes</a></span>(TIME, DV)) <span class="op">+</span><span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/geom_path">geom_line</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/aes">aes</a></span>(<span class="dt">group=</span>ID), <span class="dt">col=</span><span class="st">"red"</span>) <span class="op">+</span><span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/scale_continuous">scale_x_continuous</a></span>(<span class="st">"Time (h)"</span>) <span class="op">+</span><span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/scale_continuous">scale_y_continuous</a></span>(<span class="st">"Concentration"</span>) <span class="op">+</span><span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/labs">labs</a></span>(<span class="dt">title=</span><span class="st">"Theophylline single-dose"</span>, <span class="dt">subtitle=</span><span class="st">"Concentration vs. time by individual"</span>)</code></pre></div>
<p><img src="running_nlmixr_files/figure-html/unnamed-chunk-1-1.png" width="700"></p>
<p>We can try fitting a simple one-compartment PK model to this small dataset. We write the model as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">one.cmt &lt;-<span class="st"> </span><span class="cf">function</span>() {
    <span class="kw"><a href="../reference/ini.html">ini</a></span>({
        tka &lt;-<span class="st"> </span><span class="fl">0.45</span> <span class="co"># Log Ka</span>
        tcl &lt;-<span class="st"> </span><span class="dv">1</span> <span class="co"># Log Cl</span>
        tv &lt;-<span class="st"> </span><span class="fl">3.45</span>    <span class="co"># Log V</span>
        eta.ka <span class="op">~</span><span class="st"> </span><span class="fl">0.6</span>
        eta.cl <span class="op">~</span><span class="st"> </span><span class="fl">0.3</span>
        eta.v <span class="op">~</span><span class="st"> </span><span class="fl">0.1</span>
        add.err &lt;-<span class="st"> </span><span class="fl">0.7</span>
    })
    <span class="kw"><a href="../reference/model.html">model</a></span>({
        ka &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Log">exp</a></span>(tka <span class="op">+</span><span class="st"> </span>eta.ka)
        cl &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Log">exp</a></span>(tcl <span class="op">+</span><span class="st"> </span>eta.cl)
        v &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Log">exp</a></span>(tv <span class="op">+</span><span class="st"> </span>eta.v)
        <span class="kw">linCmt</span>() <span class="op">~</span><span class="st"> </span><span class="kw">add</span>(add.err)
    })
}</code></pre></div>
<p>We can now run the model…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw"><a href="../reference/nlmixr.html">nlmixr</a></span>(one.cmt, theo_sd, <span class="dt">est=</span><span class="st">"nlme"</span>)</code></pre></div>
<pre><code>## 
## **Iteration 1
## LME step: Loglik: -183.2149, nlminb iterations: 1
## reStruct  parameters:
##       ID1       ID2       ID3 
## 0.2198819 0.9924203 1.6504986 
##  Beginning PNLS step: ..  completed fit_nlme() step.
## PNLS step: RSS =  64.12713 
##  fixed effects: 0.445205  1.01864  3.449067  
##  iterations: 7 
## Convergence crit. (must all become &lt;= tolerance = 1e-05):
##      fixed   reStruct 
## 0.01829917 0.87183808 
## 
## **Iteration 2
## LME step: Loglik: -179.7485, nlminb iterations: 7
## reStruct  parameters:
##       ID1       ID2       ID3 
## 0.1098767 0.9674593 1.6403262 
##  Beginning PNLS step: ..  completed fit_nlme() step.
## PNLS step: RSS =  64.05998 
##  fixed effects: 0.4465211  1.01853  3.449222  
##  iterations: 7 
## Convergence crit. (must all become &lt;= tolerance = 1e-05):
##       fixed    reStruct 
## 0.002947515 0.043196731 
## 
## **Iteration 3
## LME step: Loglik: -179.7363, nlminb iterations: 5
## reStruct  parameters:
##       ID1       ID2       ID3 
## 0.1132780 0.9676318 1.6413590 
##  Beginning PNLS step: ..  completed fit_nlme() step.
## PNLS step: RSS =  64.06906 
##  fixed effects: 0.4465211  1.01853  3.449222  
##  iterations: 1 
## Convergence crit. (must all become &lt;= tolerance = 1e-05):
##       fixed    reStruct 
## 0.000000000 0.005871188 
## 
## **Iteration 4
## LME step: Loglik: -179.7363, nlminb iterations: 1
## reStruct  parameters:
##       ID1       ID2       ID3 
## 0.1132693 0.9676245 1.6413628 
##  Beginning PNLS step: ..  completed fit_nlme() step.
## PNLS step: RSS =  64.06906 
##  fixed effects: 0.4465211  1.01853  3.449222  
##  iterations: 1 
## Convergence crit. (must all become &lt;= tolerance = 1e-05):
##        fixed     reStruct 
## 0.000000e+00 2.008282e-10</code></pre>
<pre><code>## Calculating residuals/tables</code></pre>
<pre><code>## done.</code></pre>
<pre><code>## Warning in (function (uif, data, est = NULL, control = list(), ...,
## sum.prod = FALSE, : Initial condition for additive error ignored with nlme</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/print">print</a></span>(fit)</code></pre></div>
<pre><code>## ── nlmixr nlme by maximum likelihood (Solved; μ-ref &amp; covs) nlme OBF fit ── 
##          OBJF      AIC      BIC Log-likelihood Condition Number
## nlme 116.8727 373.4725 393.6521      -179.7363         17.08747
## 
## ── Time (sec; $time): ───────────────────────────────────────────────────── 
##          nlme    setup table    other
## elapsed 8.717 0.793136 0.012 0.230864
## 
## ── Population Parameters ($parFixed or $parFixedDf): ────────────────────── 
##         Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%)
## tka        Log Ka 0.447  0.192   43       1.56 (1.07, 2.28)     68.7
## tcl        Log Cl  1.02 0.0847 8.31       2.77 (2.35, 3.27)     26.9
## tv          Log V  3.45 0.0464 1.35       31.5 (28.7, 34.5)     13.6
## add.err           0.697                               0.697         
##         Shrink(SD)%
## tka         0.241% 
## tcl          3.78% 
## tv           10.0% 
## add.err             
## 
##   Covariance Type ($covMethod): nlme
##   No correlations in between subject variability (BSV) matrix
##   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs) 
##   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink 
## 
## ── Fit Data (object is a modified tibble): ──────────────────────────────── 
## # A tibble: 132 x 18
##   ID     TIME    DV  EVID  PRED    RES IPRED   IRES  IWRES eta.ka eta.cl
##   &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1 1     0      0.74     0  0     0.74   0     0.74   1.06   0.101 -0.479
## 2 1     0.25   2.84     0  3.25 -0.410  3.84 -1.00  -1.44   0.101 -0.479
## 3 1     0.570  6.57     0  5.83  0.744  6.78 -0.212 -0.305  0.101 -0.479
## # … with 129 more rows, and 7 more variables: eta.v &lt;dbl&gt;, rx1c &lt;dbl&gt;,
## #   ka &lt;dbl&gt;, cl &lt;dbl&gt;, v &lt;dbl&gt;, depot &lt;dbl&gt;, central &lt;dbl&gt;</code></pre>
<p>We can alternatively express the same model by ordinary differential equations (ODEs):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">one.compartment &lt;-<span class="st"> </span><span class="cf">function</span>() {
    <span class="kw"><a href="../reference/ini.html">ini</a></span>({
        tka &lt;-<span class="st"> </span><span class="fl">0.45</span> <span class="co"># Log Ka</span>
        tcl &lt;-<span class="st"> </span><span class="dv">1</span> <span class="co"># Log Cl</span>
        tv &lt;-<span class="st"> </span><span class="fl">3.45</span>    <span class="co"># Log V</span>
        eta.ka <span class="op">~</span><span class="st"> </span><span class="fl">0.6</span>
        eta.cl <span class="op">~</span><span class="st"> </span><span class="fl">0.3</span>
        eta.v <span class="op">~</span><span class="st"> </span><span class="fl">0.1</span>
        add.err &lt;-<span class="st"> </span><span class="fl">0.7</span>
    })
    <span class="kw"><a href="../reference/model.html">model</a></span>({
        ka &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Log">exp</a></span>(tka <span class="op">+</span><span class="st"> </span>eta.ka)
        cl &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Log">exp</a></span>(tcl <span class="op">+</span><span class="st"> </span>eta.cl)
        v &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Log">exp</a></span>(tv <span class="op">+</span><span class="st"> </span>eta.v)
        d<span class="op">/</span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/TDist">dt</a></span>(depot) =<span class="st"> </span><span class="op">-</span>ka <span class="op">*</span><span class="st"> </span>depot
        d<span class="op">/</span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/TDist">dt</a></span>(center) =<span class="st"> </span>ka <span class="op">*</span><span class="st"> </span>depot <span class="op">-</span><span class="st"> </span>cl <span class="op">/</span><span class="st"> </span>v <span class="op">*</span><span class="st"> </span>center
        cp =<span class="st"> </span>center <span class="op">/</span><span class="st"> </span>v
        cp <span class="op">~</span><span class="st"> </span><span class="kw">add</span>(add.err)
    })
}</code></pre></div>
<p>We can try the Stochastic Approximation EM (SAEM) method to this model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw"><a href="../reference/nlmixr.html">nlmixr</a></span>(one.compartment, theo_sd, <span class="dt">est=</span><span class="st">"saem"</span>)</code></pre></div>
<pre><code>## Compiling RxODE equations...done.</code></pre>
<pre><code>## 1:    0.2288   0.9677   3.4737   0.5700   0.2850   0.0950   4.5245
## 2:    0.3623   0.9821   3.5318   0.5415   0.2707   0.0902   1.8046
## 3:    0.4864   0.9181   3.4872   0.5144   0.2572   0.0857   0.9422
## 4:    0.4480   0.9416   3.4843   0.4887   0.2444   0.0815   0.6940
## 5:    0.4844   0.9591   3.4754   0.4643   0.2321   0.0774   0.6019
## 6:    0.4986   0.9687   3.4752   0.4411   0.2205   0.0735   0.5056
## 7:    0.4577   0.9953   3.4634   0.4251   0.2095   0.0698   0.5076
## 8:    0.4473   0.9911   3.4666   0.4039   0.1990   0.0663   0.5155
## 9:    0.4188   0.9755   3.4615   0.3837   0.1891   0.0630   0.5210
## 10:    0.4349   0.9798   3.4521   0.4305   0.1796   0.0599   0.4901
## 11:    0.4537   0.9976   3.4548   0.4089   0.1706   0.0569   0.4911
## 12:    0.4421   1.0104   3.4458   0.3885   0.1621   0.0540   0.4628
## 13:    0.3941   1.0454   3.4243   0.3691   0.1540   0.0513   0.4783
## 14:    0.4189   1.0204   3.4380   0.4545   0.1463   0.0488   0.5002
## 15:    0.4506   1.0202   3.4468   0.4318   0.1390   0.0463   0.4889
## 16:    0.4552   1.0112   3.4524   0.4209   0.1320   0.0440   0.5038
## 17:    0.4542   1.0115   3.4558   0.4164   0.1254   0.0418   0.4658
## 18:    0.4820   0.9828   3.4521   0.4451   0.1192   0.0397   0.5021
## 19:    0.4339   0.9924   3.4505   0.4228   0.1132   0.0377   0.4914
## 20:    0.4527   1.0041   3.4472   0.4037   0.1075   0.0358   0.4928
## 21:    0.4404   1.0079   3.4558   0.3885   0.1022   0.0341   0.4739
## 22:    0.4625   1.0138   3.4599   0.4469   0.0971   0.0324   0.4520
## 23:    0.5104   1.0181   3.4648   0.4535   0.0922   0.0307   0.4667
## 24:    0.5050   1.0228   3.4659   0.4308   0.0876   0.0292   0.4543
## 25:    0.4633   0.9967   3.4608   0.4093   0.0861   0.0277   0.4789
## 26:    0.4183   1.0293   3.4345   0.4183   0.0818   0.0264   0.4644
## 27:    0.4126   1.0361   3.4357   0.3973   0.0777   0.0250   0.4941
## 28:    0.4592   1.0181   3.4429   0.3775   0.0738   0.0238   0.4538
## 29:    0.4413   1.0248   3.4369   0.3586   0.0701   0.0226   0.4801
## 30:    0.4506   1.0195   3.4440   0.3689   0.0672   0.0215   0.4824
## 31:    0.4049   1.0069   3.4520   0.3505   0.0768   0.0204   0.4778
## 32:    0.4292   0.9864   3.4607   0.3939   0.0729   0.0205   0.4702
## 33:    0.4417   1.0151   3.4477   0.4332   0.0693   0.0195   0.4917
## 34:    0.4597   1.0252   3.4485   0.4238   0.0658   0.0185   0.4909
## 35:    0.4485   0.9940   3.4511   0.4026   0.0637   0.0176   0.4766
## 36:    0.4405   1.0103   3.4488   0.3825   0.0658   0.0167   0.4873
## 37:    0.4408   1.0163   3.4572   0.3731   0.0707   0.0195   0.4872
## 38:    0.5014   1.0088   3.4476   0.4544   0.0752   0.0185   0.4844
## 39:    0.5031   0.9852   3.4647   0.4819   0.0715   0.0245   0.4632
## 40:    0.4910   0.9905   3.4762   0.4578   0.0679   0.0272   0.4737
## 41:    0.4276   0.9901   3.4569   0.4349   0.0645   0.0259   0.4968
## 42:    0.4696   1.0088   3.4529   0.4236   0.0656   0.0246   0.4457
## 43:    0.4296   1.0293   3.4341   0.4025   0.0641   0.0233   0.4549
## 44:    0.4268   1.0334   3.4423   0.3823   0.0609   0.0237   0.4758
## 45:    0.4435   1.0397   3.4447   0.4115   0.0585   0.0265   0.4409
## 46:    0.4406   1.0217   3.4500   0.3910   0.0765   0.0252   0.4533
## 47:    0.4454   1.0224   3.4450   0.3841   0.0727   0.0239   0.4644
## 48:    0.4597   1.0215   3.4499   0.4516   0.0691   0.0238   0.4763
## 49:    0.4512   1.0173   3.4484   0.4290   0.0668   0.0239   0.4950
## 50:    0.4538   0.9948   3.4407   0.4076   0.0767   0.0227   0.5089
## 51:    0.4708   1.0340   3.4357   0.4159   0.0729   0.0216   0.4933
## 52:    0.5150   1.0202   3.4583   0.4959   0.0692   0.0205   0.4824
## 53:    0.5019   1.0156   3.4502   0.4711   0.0658   0.0195   0.5123
## 54:    0.4544   1.0083   3.4541   0.4476   0.0654   0.0188   0.5106
## 55:    0.4427   1.0017   3.4534   0.4252   0.0705   0.0191   0.4871
## 56:    0.4411   0.9917   3.4486   0.4039   0.0670   0.0214   0.4881
## 57:    0.4808   1.0063   3.4621   0.3957   0.0668   0.0203   0.4932
## 58:    0.5100   1.0050   3.4567   0.4291   0.0677   0.0193   0.4939
## 59:    0.5064   0.9712   3.4642   0.4676   0.0888   0.0183   0.5044
## 60:    0.4913   0.9699   3.4635   0.4897   0.0844   0.0184   0.5282
## 61:    0.5047   0.9892   3.4614   0.5644   0.0801   0.0187   0.5103
## 62:    0.4536   1.0146   3.4580   0.5362   0.0826   0.0193   0.5128
## 63:    0.4776   1.0017   3.4530   0.5094   0.0915   0.0184   0.4863
## 64:    0.4550   1.0007   3.4565   0.4839   0.0903   0.0176   0.4998
## 65:    0.4857   1.0002   3.4422   0.4597   0.0874   0.0193   0.4952
## 66:    0.4478   1.0116   3.4506   0.4368   0.0878   0.0189   0.4872
## 67:    0.4560   0.9978   3.4400   0.4149   0.0834   0.0198   0.4768
## 68:    0.4015   1.0105   3.4500   0.3942   0.0792   0.0188   0.5248
## 69:    0.4199   1.0082   3.4475   0.4043   0.0752   0.0200   0.5082
## 70:    0.4253   1.0065   3.4493   0.4755   0.0731   0.0205   0.5055
## 71:    0.4117   1.0205   3.4353   0.4518   0.0709   0.0194   0.5004
## 72:    0.4360   0.9896   3.4507   0.4292   0.0794   0.0185   0.4803
## 73:    0.4627   1.0107   3.4625   0.4077   0.0755   0.0175   0.5032
## 74:    0.4423   0.9902   3.4615   0.3951   0.0717   0.0167   0.5050
## 75:    0.4804   0.9934   3.4805   0.3992   0.0838   0.0198   0.4787
## 76:    0.5158   1.0021   3.4882   0.4126   0.0796   0.0189   0.5092
## 77:    0.5218   0.9735   3.4803   0.4015   0.0756   0.0212   0.4962
## 78:    0.4955   0.9901   3.4782   0.4149   0.0723   0.0212   0.4968
## 79:    0.4812   1.0022   3.4688   0.4388   0.0687   0.0226   0.5138
## 80:    0.4961   0.9871   3.4663   0.5095   0.0663   0.0231   0.5008
## 81:    0.5070   1.0060   3.4671   0.4841   0.0629   0.0220   0.4849
## 82:    0.4839   0.9860   3.4730   0.4599   0.0598   0.0277   0.4823
## 83:    0.4757   1.0172   3.4654   0.4473   0.0568   0.0263   0.4652
## 84:    0.4435   0.9975   3.4540   0.4364   0.0540   0.0261   0.4610
## 85:    0.4664   1.0161   3.4677   0.4214   0.0540   0.0248   0.4924
## 86:    0.4662   1.0089   3.4598   0.4003   0.0599   0.0275   0.4604
## 87:    0.4415   1.0119   3.4497   0.3899   0.0569   0.0262   0.4832
## 88:    0.3796   1.0086   3.4436   0.4004   0.0589   0.0249   0.4865
## 89:    0.4269   1.0175   3.4436   0.3804   0.0593   0.0236   0.5350
## 90:    0.4326   1.0242   3.4437   0.4088   0.0563   0.0224   0.5157
## 91:    0.4446   1.0109   3.4282   0.4562   0.0597   0.0216   0.4853
## 92:    0.4320   1.0268   3.4386   0.5057   0.0691   0.0236   0.4781
## 93:    0.3564   1.0149   3.4338   0.4804   0.0698   0.0224   0.5011
## 94:    0.3878   1.0151   3.4224   0.4563   0.0727   0.0213   0.5119
## 95:    0.4563   1.0220   3.4455   0.5434   0.0709   0.0202   0.5027
## 96:    0.4575   1.0088   3.4446   0.5162   0.0673   0.0206   0.4731
## 97:    0.4498   1.0277   3.4474   0.4904   0.0640   0.0197   0.4830
## 98:    0.4713   1.0243   3.4547   0.4659   0.0617   0.0187   0.4752
## 99:    0.4413   1.0028   3.4478   0.4426   0.0587   0.0194   0.4663
## 100:    0.4279   1.0081   3.4471   0.4205   0.0648   0.0213   0.4570
## 101:    0.4195   1.0062   3.4350   0.4386   0.0788   0.0202   0.4638
## 102:    0.4093   1.0121   3.4290   0.4565   0.0749   0.0192   0.4679
## 103:    0.4730   1.0048   3.4494   0.4635   0.0711   0.0201   0.4593
## 104:    0.4535   1.0068   3.4564   0.4917   0.0693   0.0193   0.4936
## 105:    0.4404   1.0082   3.4391   0.5036   0.0828   0.0183   0.5014
## 106:    0.4470   1.0029   3.4488   0.4785   0.0839   0.0174   0.4972
## 107:    0.4493   1.0090   3.4480   0.4990   0.0820   0.0166   0.4727
## 108:    0.4533   1.0076   3.4550   0.4741   0.0779   0.0178   0.4784
## 109:    0.4513   1.0176   3.4609   0.4504   0.0740   0.0176   0.4651
## 110:    0.4804   0.9923   3.4544   0.4616   0.0703   0.0187   0.4615
## 111:    0.4768   0.9979   3.4601   0.4385   0.0801   0.0178   0.4392
## 112:    0.4809   0.9864   3.4540   0.4495   0.0761   0.0187   0.4452
## 113:    0.4422   1.0386   3.4474   0.4592   0.0723   0.0182   0.4465
## 114:    0.4311   1.0411   3.4368   0.4363   0.0771   0.0190   0.4466
## 115:    0.4261   1.0006   3.4460   0.4145   0.0733   0.0197   0.4811
## 116:    0.4618   1.0050   3.4459   0.4178   0.0696   0.0190   0.4804
## 117:    0.4243   1.0276   3.4502   0.3969   0.0758   0.0181   0.4830
## 118:    0.4661   1.0209   3.4537   0.3771   0.0798   0.0177   0.4902
## 119:    0.4684   1.0132   3.4548   0.4747   0.0838   0.0220   0.5065
## 120:    0.4260   1.0016   3.4485   0.4611   0.0796   0.0209   0.4749
## 121:    0.4415   1.0288   3.4409   0.4380   0.0756   0.0199   0.4814
## 122:    0.4389   1.0077   3.4469   0.4161   0.0719   0.0189   0.4544
## 123:    0.4391   1.0456   3.4443   0.4249   0.0683   0.0203   0.4614
## 124:    0.4663   1.0506   3.4504   0.4291   0.0669   0.0197   0.4463
## 125:    0.4714   1.0387   3.4485   0.4077   0.0829   0.0188   0.4568
## 126:    0.4426   1.0411   3.4412   0.4396   0.0891   0.0189   0.4532
## 127:    0.4472   1.0047   3.4338   0.4235   0.0859   0.0206   0.4881
## 128:    0.4413   1.0274   3.4457   0.4504   0.0817   0.0258   0.5163
## 129:    0.4669   1.0151   3.4652   0.4828   0.0776   0.0245   0.4812
## 130:    0.5358   1.0291   3.4502   0.5114   0.0737   0.0233   0.4844
## 131:    0.4486   1.0021   3.4407   0.4858   0.0757   0.0223   0.4845
## 132:    0.4105   1.0228   3.4263   0.4615   0.0845   0.0212   0.5082
## 133:    0.4199   1.0085   3.4401   0.4384   0.0803   0.0201   0.5018
## 134:    0.4689   1.0094   3.4565   0.4267   0.0763   0.0216   0.4707
## 135:    0.4788   0.9996   3.4608   0.4429   0.0725   0.0212   0.4738
## 136:    0.4736   0.9941   3.4609   0.4257   0.0721   0.0202   0.4765
## 137:    0.5135   1.0050   3.4650   0.4808   0.0685   0.0192   0.4929
## 138:    0.5037   1.0134   3.4640   0.4617   0.0673   0.0182   0.4583
## 139:    0.4580   1.0140   3.4590   0.4430   0.0695   0.0173   0.4582
## 140:    0.4554   1.0406   3.4555   0.4401   0.0692   0.0165   0.4809
## 141:    0.4652   1.0116   3.4584   0.4410   0.0732   0.0167   0.4540
## 142:    0.4681   0.9963   3.4702   0.4189   0.0738   0.0164   0.4898
## 143:    0.4680   1.0157   3.4646   0.4407   0.0833   0.0195   0.4852
## 144:    0.5092   1.0186   3.4736   0.4186   0.0791   0.0185   0.4794
## 145:    0.4775   1.0224   3.4537   0.4057   0.0751   0.0194   0.4598
## 146:    0.4477   1.0231   3.4559   0.4141   0.0755   0.0184   0.4565
## 147:    0.4491   1.0038   3.4440   0.3934   0.0717   0.0175   0.4539
## 148:    0.4138   1.0081   3.4505   0.3766   0.0681   0.0167   0.4592
## 149:    0.4358   1.0014   3.4566   0.3593   0.0740   0.0181   0.4525
## 150:    0.4642   0.9971   3.4466   0.3686   0.0714   0.0172   0.4834
## 151:    0.3957   1.0290   3.4428   0.3502   0.0678   0.0166   0.4597
## 152:    0.4385   1.0303   3.4418   0.4135   0.0751   0.0182   0.4428
## 153:    0.4311   1.0241   3.4551   0.4449   0.0695   0.0211   0.4585
## 154:    0.4526   1.0361   3.4580   0.4451   0.0804   0.0216   0.4675
## 155:    0.4456   1.0099   3.4491   0.5220   0.0655   0.0260   0.4651
## 156:    0.4692   1.0232   3.4570   0.4744   0.0750   0.0272   0.4873
## 157:    0.4455   1.0076   3.4554   0.4163   0.0657   0.0275   0.4962
## 158:    0.4667   1.0137   3.4557   0.4095   0.0575   0.0256   0.4879
## 159:    0.4116   1.0284   3.4529   0.3624   0.0561   0.0203   0.4950
## 160:    0.4460   0.9918   3.4546   0.4222   0.0633   0.0187   0.4917
## 161:    0.4045   1.0219   3.4411   0.3363   0.0583   0.0210   0.4802
## 162:    0.4111   1.0408   3.4360   0.4027   0.0551   0.0216   0.4717
## 163:    0.4583   1.0217   3.4334   0.4395   0.0513   0.0194   0.4768
## 164:    0.4343   1.0235   3.4361   0.4231   0.0466   0.0197   0.4779
## 165:    0.4498   1.0205   3.4460   0.4112   0.0505   0.0209   0.4710
## 166:    0.4655   1.0353   3.4502   0.4515   0.0434   0.0244   0.4772
## 167:    0.4715   1.0477   3.4591   0.3925   0.0515   0.0259   0.4848
## 168:    0.4719   1.0397   3.4566   0.3975   0.0533   0.0251   0.4815
## 169:    0.4835   1.0503   3.4514   0.3927   0.0596   0.0228   0.4881
## 170:    0.4904   1.0318   3.4596   0.3819   0.0535   0.0245   0.4970
## 171:    0.4790   1.0233   3.4594   0.3958   0.0581   0.0266   0.4693
## 172:    0.4367   1.0286   3.4543   0.3950   0.0483   0.0240   0.4750
## 173:    0.4349   1.0299   3.4430   0.3543   0.0537   0.0328   0.4562
## 174:    0.4384   1.0341   3.4546   0.3507   0.0429   0.0312   0.4850
## 175:    0.4110   1.0363   3.4397   0.3697   0.0562   0.0320   0.4905
## 176:    0.4096   1.0352   3.4566   0.3879   0.0568   0.0247   0.4872
## 177:    0.4624   1.0183   3.4540   0.4842   0.0609   0.0292   0.4606
## 178:    0.4544   1.0014   3.4640   0.4038   0.0670   0.0248   0.4518
## 179:    0.4937   1.0053   3.4593   0.4311   0.0793   0.0215   0.4725
## 180:    0.4610   1.0052   3.4684   0.3130   0.0739   0.0202   0.4899
## 181:    0.4457   1.0111   3.4327   0.3551   0.0622   0.0206   0.4881
## 182:    0.4208   1.0181   3.4365   0.3383   0.0822   0.0203   0.4912
## 183:    0.4391   1.0126   3.4420   0.3760   0.0710   0.0206   0.4885
## 184:    0.4328   1.0152   3.4418   0.4418   0.0662   0.0201   0.4694
## 185:    0.4007   1.0374   3.4336   0.4132   0.0730   0.0258   0.4663
## 186:    0.3875   1.0509   3.4277   0.4124   0.0737   0.0292   0.4863
## 187:    0.4129   1.0251   3.4382   0.3934   0.0605   0.0311   0.4913
## 188:    0.4050   1.0465   3.4394   0.4021   0.0719   0.0252   0.4824
## 189:    0.4270   1.0324   3.4475   0.4149   0.0642   0.0241   0.4776
## 190:    0.4604   1.0185   3.4590   0.3588   0.0572   0.0247   0.4623
## 191:    0.4564   1.0253   3.4565   0.3920   0.0646   0.0253   0.4507
## 192:    0.4462   1.0148   3.4547   0.3613   0.0745   0.0207   0.4635
## 193:    0.4690   1.0323   3.4516   0.3870   0.0699   0.0217   0.4650
## 194:    0.4237   1.0227   3.4307   0.4119   0.0629   0.0157   0.4844
## 195:    0.4132   1.0418   3.4191   0.3738   0.0626   0.0156   0.4908
## 196:    0.4215   1.0304   3.4331   0.4396   0.0816   0.0158   0.4810
## 197:    0.3767   1.0441   3.4434   0.3869   0.0706   0.0170   0.5149
## 198:    0.4390   1.0243   3.4298   0.4769   0.0739   0.0175   0.4693
## 199:    0.4173   1.0072   3.4381   0.4556   0.0734   0.0178   0.4568
## 200:    0.4224   1.0074   3.4394   0.4044   0.0729   0.0193   0.4768
## 201:    0.4245   1.0067   3.4442   0.3952   0.0739   0.0198   0.4715
## 202:    0.4220   1.0110   3.4439   0.4072   0.0720   0.0211   0.4728
## 203:    0.4319   1.0094   3.4422   0.4291   0.0726   0.0217   0.4677
## 204:    0.4344   1.0041   3.4441   0.4368   0.0729   0.0208   0.4693
## 205:    0.4370   1.0086   3.4435   0.4327   0.0743   0.0211   0.4724
## 206:    0.4413   1.0141   3.4445   0.4392   0.0737   0.0208   0.4756
## 207:    0.4372   1.0164   3.4436   0.4333   0.0716   0.0207   0.4763
## 208:    0.4371   1.0162   3.4439   0.4237   0.0692   0.0210   0.4770
## 209:    0.4388   1.0155   3.4436   0.4289   0.0681   0.0211   0.4751
## 210:    0.4398   1.0138   3.4447   0.4288   0.0674   0.0211   0.4734
## 211:    0.4438   1.0140   3.4459   0.4319   0.0679   0.0210   0.4713
## 212:    0.4469   1.0123   3.4466   0.4305   0.0677   0.0208   0.4713
## 213:    0.4485   1.0098   3.4471   0.4290   0.0681   0.0205   0.4730
## 214:    0.4530   1.0094   3.4477   0.4334   0.0690   0.0203   0.4742
## 215:    0.4545   1.0090   3.4489   0.4332   0.0699   0.0202   0.4744
## 216:    0.4583   1.0073   3.4497   0.4417   0.0700   0.0201   0.4762
## 217:    0.4604   1.0077   3.4503   0.4452   0.0699   0.0201   0.4759
## 218:    0.4626   1.0079   3.4503   0.4496   0.0696   0.0201   0.4763
## 219:    0.4624   1.0075   3.4498   0.4515   0.0693   0.0200   0.4768
## 220:    0.4602   1.0079   3.4497   0.4489   0.0691   0.0200   0.4768
## 221:    0.4581   1.0083   3.4493   0.4453   0.0688   0.0201   0.4768
## 222:    0.4584   1.0087   3.4494   0.4475   0.0686   0.0202   0.4772
## 223:    0.4601   1.0084   3.4499   0.4486   0.0683   0.0204   0.4766
## 224:    0.4629   1.0089   3.4505   0.4514   0.0681   0.0206   0.4759
## 225:    0.4630   1.0076   3.4510   0.4510   0.0679   0.0206   0.4761
## 226:    0.4642   1.0062   3.4513   0.4513   0.0680   0.0207   0.4762
## 227:    0.4646   1.0059   3.4516   0.4495   0.0682   0.0207   0.4758
## 228:    0.4647   1.0068   3.4514   0.4491   0.0680   0.0207   0.4761
## 229:    0.4643   1.0066   3.4512   0.4489   0.0678   0.0208   0.4759
## 230:    0.4635   1.0067   3.4508   0.4473   0.0678   0.0209   0.4760
## 231:    0.4631   1.0070   3.4511   0.4443   0.0675   0.0210   0.4762
## 232:    0.4629   1.0071   3.4513   0.4432   0.0674   0.0209   0.4757
## 233:    0.4623   1.0063   3.4515   0.4448   0.0673   0.0209   0.4762
## 234:    0.4615   1.0065   3.4515   0.4432   0.0672   0.0209   0.4765
## 235:    0.4608   1.0064   3.4511   0.4419   0.0670   0.0210   0.4762
## 236:    0.4606   1.0071   3.4509   0.4405   0.0669   0.0210   0.4761
## 237:    0.4607   1.0067   3.4511   0.4405   0.0669   0.0211   0.4767
## 238:    0.4611   1.0073   3.4510   0.4401   0.0671   0.0211   0.4779
## 239:    0.4608   1.0078   3.4510   0.4394   0.0672   0.0210   0.4780
## 240:    0.4609   1.0079   3.4512   0.4390   0.0674   0.0210   0.4776
## 241:    0.4620   1.0072   3.4514   0.4393   0.0676   0.0210   0.4776
## 242:    0.4624   1.0069   3.4514   0.4384   0.0680   0.0210   0.4779
## 243:    0.4624   1.0072   3.4514   0.4370   0.0684   0.0210   0.4780
## 244:    0.4619   1.0073   3.4516   0.4345   0.0687   0.0209   0.4786
## 245:    0.4618   1.0068   3.4519   0.4321   0.0688   0.0208   0.4791
## 246:    0.4620   1.0065   3.4520   0.4303   0.0690   0.0208   0.4797
## 247:    0.4624   1.0065   3.4523   0.4300   0.0692   0.0209   0.4800
## 248:    0.4626   1.0065   3.4526   0.4290   0.0691   0.0209   0.4797
## 249:    0.4622   1.0067   3.4526   0.4280   0.0691   0.0209   0.4795
## 250:    0.4630   1.0072   3.4529   0.4283   0.0690   0.0209   0.4794
## 251:    0.4640   1.0074   3.4533   0.4293   0.0691   0.0209   0.4790
## 252:    0.4646   1.0076   3.4538   0.4306   0.0690   0.0209   0.4791
## 253:    0.4647   1.0078   3.4540   0.4311   0.0688   0.0209   0.4795
## 254:    0.4644   1.0081   3.4542   0.4316   0.0689   0.0208   0.4795
## 255:    0.4641   1.0085   3.4543   0.4304   0.0690   0.0209   0.4797
## 256:    0.4640   1.0086   3.4542   0.4303   0.0689   0.0209   0.4792
## 257:    0.4636   1.0082   3.4541   0.4300   0.0687   0.0208   0.4790
## 258:    0.4634   1.0079   3.4539   0.4316   0.0688   0.0209   0.4786
## 259:    0.4631   1.0077   3.4538   0.4314   0.0689   0.0209   0.4781
## 260:    0.4628   1.0080   3.4539   0.4310   0.0688   0.0209   0.4780
## 261:    0.4631   1.0080   3.4541   0.4300   0.0688   0.0209   0.4779
## 262:    0.4628   1.0082   3.4541   0.4287   0.0690   0.0209   0.4778
## 263:    0.4626   1.0083   3.4542   0.4280   0.0689   0.0209   0.4778
## 264:    0.4621   1.0087   3.4541   0.4281   0.0689   0.0208   0.4781
## 265:    0.4621   1.0089   3.4540   0.4285   0.0692   0.0208   0.4782
## 266:    0.4620   1.0092   3.4539   0.4300   0.0691   0.0207   0.4782
## 267:    0.4617   1.0096   3.4538   0.4320   0.0692   0.0207   0.4783
## 268:    0.4620   1.0098   3.4536   0.4329   0.0691   0.0207   0.4786
## 269:    0.4622   1.0099   3.4535   0.4326   0.0691   0.0206   0.4788
## 270:    0.4622   1.0103   3.4532   0.4333   0.0692   0.0206   0.4785
## 271:    0.4621   1.0107   3.4530   0.4330   0.0691   0.0205   0.4787
## 272:    0.4623   1.0107   3.4528   0.4326   0.0693   0.0205   0.4790
## 273:    0.4619   1.0111   3.4528   0.4316   0.0695   0.0205   0.4791
## 274:    0.4618   1.0114   3.4529   0.4301   0.0697   0.0204   0.4792
## 275:    0.4618   1.0115   3.4529   0.4293   0.0699   0.0204   0.4789
## 276:    0.4615   1.0116   3.4529   0.4290   0.0700   0.0203   0.4788
## 277:    0.4606   1.0117   3.4529   0.4281   0.0699   0.0203   0.4789
## 278:    0.4603   1.0116   3.4529   0.4280   0.0697   0.0203   0.4791
## 279:    0.4602   1.0114   3.4530   0.4281   0.0695   0.0203   0.4793
## 280:    0.4602   1.0114   3.4532   0.4279   0.0695   0.0203   0.4792
## 281:    0.4604   1.0115   3.4534   0.4283   0.0694   0.0203   0.4792
## 282:    0.4609   1.0118   3.4535   0.4296   0.0695   0.0202   0.4792
## 283:    0.4610   1.0120   3.4536   0.4308   0.0694   0.0202   0.4799
## 284:    0.4605   1.0121   3.4534   0.4321   0.0693   0.0202   0.4800
## 285:    0.4600   1.0124   3.4531   0.4318   0.0692   0.0202   0.4798
## 286:    0.4595   1.0128   3.4529   0.4320   0.0692   0.0201   0.4797
## 287:    0.4589   1.0133   3.4525   0.4321   0.0693   0.0201   0.4796
## 288:    0.4587   1.0134   3.4523   0.4316   0.0694   0.0201   0.4798
## 289:    0.4579   1.0134   3.4521   0.4304   0.0695   0.0201   0.4799
## 290:    0.4577   1.0135   3.4519   0.4304   0.0696   0.0201   0.4800
## 291:    0.4577   1.0140   3.4519   0.4310   0.0697   0.0201   0.4799
## 292:    0.4577   1.0141   3.4517   0.4316   0.0699   0.0201   0.4799
## 293:    0.4575   1.0141   3.4516   0.4319   0.0699   0.0201   0.4802
## 294:    0.4575   1.0141   3.4514   0.4323   0.0699   0.0202   0.4804
## 295:    0.4574   1.0138   3.4514   0.4326   0.0699   0.0202   0.4803
## 296:    0.4572   1.0139   3.4515   0.4318   0.0698   0.0202   0.4805
## 297:    0.4571   1.0140   3.4514   0.4320   0.0698   0.0203   0.4806
## 298:    0.4571   1.0140   3.4514   0.4314   0.0698   0.0203   0.4808
## 299:    0.4573   1.0140   3.4514   0.4317   0.0699   0.0202   0.4809
## 300:    0.4575   1.0140   3.4515   0.4322   0.0699   0.0202   0.4808
## 301:    0.4577   1.0138   3.4514   0.4315   0.0699   0.0201   0.4808
## 302:    0.4579   1.0139   3.4515   0.4309   0.0699   0.0201   0.4806
## 303:    0.4582   1.0138   3.4516   0.4304   0.0699   0.0202   0.4804
## 304:    0.4583   1.0140   3.4516   0.4309   0.0698   0.0202   0.4804
## 305:    0.4584   1.0138   3.4515   0.4304   0.0698   0.0202   0.4805
## 306:    0.4579   1.0139   3.4513   0.4301   0.0698   0.0202   0.4805
## 307:    0.4575   1.0138   3.4512   0.4292   0.0698   0.0202   0.4807
## 308:    0.4571   1.0137   3.4510   0.4291   0.0698   0.0202   0.4809
## 309:    0.4566   1.0135   3.4509   0.4291   0.0698   0.0202   0.4812
## 310:    0.4566   1.0135   3.4507   0.4294   0.0699   0.0202   0.4816
## 311:    0.4567   1.0133   3.4507   0.4296   0.0699   0.0201   0.4816
## 312:    0.4564   1.0133   3.4506   0.4300   0.0701   0.0201   0.4817
## 313:    0.4561   1.0131   3.4504   0.4300   0.0701   0.0200   0.4820
## 314:    0.4556   1.0129   3.4504   0.4296   0.0701   0.0200   0.4821
## 315:    0.4555   1.0129   3.4504   0.4296   0.0701   0.0199   0.4821
## 316:    0.4556   1.0130   3.4503   0.4297   0.0702   0.0199   0.4821
## 317:    0.4556   1.0132   3.4503   0.4290   0.0702   0.0199   0.4821
## 318:    0.4556   1.0134   3.4503   0.4286   0.0702   0.0199   0.4821
## 319:    0.4554   1.0135   3.4503   0.4279   0.0702   0.0199   0.4823
## 320:    0.4551   1.0134   3.4502   0.4278   0.0702   0.0198   0.4823
## 321:    0.4546   1.0136   3.4500   0.4277   0.0701   0.0198   0.4823
## 322:    0.4547   1.0136   3.4499   0.4287   0.0701   0.0198   0.4822
## 323:    0.4546   1.0136   3.4498   0.4291   0.0701   0.0198   0.4820
## 324:    0.4544   1.0138   3.4497   0.4298   0.0701   0.0198   0.4819
## 325:    0.4544   1.0140   3.4496   0.4298   0.0701   0.0198   0.4818
## 326:    0.4542   1.0139   3.4495   0.4298   0.0701   0.0198   0.4817
## 327:    0.4545   1.0141   3.4495   0.4309   0.0701   0.0198   0.4815
## 328:    0.4545   1.0141   3.4494   0.4315   0.0701   0.0198   0.4815
## 329:    0.4547   1.0142   3.4495   0.4318   0.0701   0.0198   0.4814
## 330:    0.4544   1.0142   3.4495   0.4317   0.0701   0.0198   0.4813
## 331:    0.4544   1.0143   3.4495   0.4311   0.0701   0.0198   0.4813
## 332:    0.4545   1.0145   3.4496   0.4310   0.0701   0.0198   0.4814
## 333:    0.4546   1.0145   3.4495   0.4313   0.0702   0.0197   0.4815
## 334:    0.4543   1.0145   3.4494   0.4314   0.0702   0.0197   0.4814
## 335:    0.4543   1.0146   3.4492   0.4318   0.0703   0.0197   0.4813
## 336:    0.4536   1.0149   3.4490   0.4318   0.0704   0.0197   0.4814
## 337:    0.4533   1.0153   3.4488   0.4322   0.0706   0.0197   0.4812
## 338:    0.4533   1.0155   3.4488   0.4323   0.0708   0.0197   0.4811
## 339:    0.4532   1.0157   3.4488   0.4318   0.0708   0.0196   0.4811
## 340:    0.4532   1.0155   3.4488   0.4318   0.0709   0.0196   0.4811
## 341:    0.4535   1.0154   3.4489   0.4317   0.0709   0.0196   0.4811
## 342:    0.4534   1.0153   3.4489   0.4312   0.0709   0.0196   0.4811
## 343:    0.4532   1.0153   3.4489   0.4307   0.0710   0.0196   0.4810
## 344:    0.4532   1.0153   3.4489   0.4306   0.0709   0.0196   0.4810
## 345:    0.4533   1.0153   3.4490   0.4303   0.0708   0.0196   0.4810
## 346:    0.4531   1.0154   3.4489   0.4300   0.0707   0.0196   0.4809
## 347:    0.4529   1.0155   3.4488   0.4300   0.0707   0.0196   0.4809
## 348:    0.4526   1.0156   3.4486   0.4300   0.0706   0.0196   0.4810
## 349:    0.4523   1.0157   3.4485   0.4301   0.0706   0.0196   0.4810
## 350:    0.4520   1.0157   3.4484   0.4301   0.0705   0.0196   0.4809
## 351:    0.4519   1.0157   3.4483   0.4303   0.0704   0.0196   0.4809
## 352:    0.4517   1.0158   3.4482   0.4303   0.0703   0.0196   0.4811
## 353:    0.4519   1.0160   3.4482   0.4305   0.0703   0.0196   0.4811
## 354:    0.4519   1.0160   3.4481   0.4304   0.0703   0.0196   0.4811
## 355:    0.4521   1.0160   3.4481   0.4305   0.0704   0.0196   0.4810
## 356:    0.4520   1.0158   3.4481   0.4298   0.0704   0.0196   0.4811
## 357:    0.4519   1.0159   3.4481   0.4296   0.0704   0.0196   0.4811
## 358:    0.4519   1.0160   3.4482   0.4291   0.0704   0.0195   0.4809
## 359:    0.4517   1.0161   3.4482   0.4288   0.0704   0.0195   0.4808
## 360:    0.4515   1.0160   3.4481   0.4289   0.0704   0.0195   0.4807
## 361:    0.4512   1.0161   3.4481   0.4283   0.0703   0.0195   0.4806
## 362:    0.4511   1.0161   3.4481   0.4281   0.0703   0.0195   0.4804
## 363:    0.4511   1.0160   3.4481   0.4280   0.0702   0.0195   0.4802
## 364:    0.4512   1.0160   3.4481   0.4282   0.0701   0.0195   0.4802
## 365:    0.4512   1.0158   3.4482   0.4281   0.0701   0.0196   0.4802
## 366:    0.4510   1.0158   3.4482   0.4274   0.0700   0.0196   0.4804
## 367:    0.4510   1.0158   3.4482   0.4270   0.0700   0.0196   0.4804
## 368:    0.4511   1.0158   3.4482   0.4270   0.0700   0.0196   0.4803
## 369:    0.4513   1.0158   3.4482   0.4273   0.0700   0.0196   0.4802
## 370:    0.4514   1.0157   3.4483   0.4271   0.0699   0.0196   0.4803
## 371:    0.4513   1.0158   3.4482   0.4269   0.0700   0.0197   0.4802
## 372:    0.4509   1.0161   3.4481   0.4266   0.0700   0.0197   0.4802
## 373:    0.4505   1.0163   3.4479   0.4263   0.0700   0.0197   0.4801
## 374:    0.4502   1.0164   3.4478   0.4260   0.0700   0.0196   0.4800
## 375:    0.4499   1.0164   3.4477   0.4258   0.0700   0.0196   0.4799
## 376:    0.4496   1.0166   3.4477   0.4254   0.0700   0.0196   0.4798
## 377:    0.4494   1.0167   3.4477   0.4251   0.0700   0.0196   0.4796
## 378:    0.4492   1.0167   3.4476   0.4250   0.0700   0.0196   0.4796
## 379:    0.4490   1.0166   3.4475   0.4251   0.0700   0.0196   0.4796
## 380:    0.4488   1.0166   3.4474   0.4250   0.0701   0.0196   0.4796
## 381:    0.4486   1.0166   3.4474   0.4249   0.0701   0.0196   0.4796
## 382:    0.4484   1.0167   3.4474   0.4245   0.0701   0.0195   0.4795
## 383:    0.4484   1.0166   3.4474   0.4244   0.0700   0.0195   0.4794
## 384:    0.4483   1.0165   3.4474   0.4240   0.0700   0.0196   0.4794
## 385:    0.4484   1.0164   3.4474   0.4242   0.0699   0.0196   0.4793
## 386:    0.4486   1.0165   3.4475   0.4243   0.0700   0.0196   0.4792
## 387:    0.4488   1.0166   3.4476   0.4239   0.0699   0.0196   0.4792
## 388:    0.4489   1.0166   3.4477   0.4240   0.0699   0.0196   0.4791
## 389:    0.4488   1.0165   3.4477   0.4239   0.0699   0.0196   0.4791
## 390:    0.4487   1.0166   3.4476   0.4238   0.0700   0.0196   0.4789
## 391:    0.4489   1.0166   3.4476   0.4238   0.0700   0.0196   0.4789
## 392:    0.4489   1.0166   3.4476   0.4239   0.0699   0.0196   0.4790
## 393:    0.4489   1.0166   3.4476   0.4241   0.0699   0.0195   0.4790
## 394:    0.4491   1.0167   3.4475   0.4241   0.0699   0.0195   0.4790
## 395:    0.4492   1.0167   3.4475   0.4236   0.0699   0.0195   0.4791
## 396:    0.4492   1.0168   3.4476   0.4237   0.0698   0.0195   0.4791
## 397:    0.4494   1.0165   3.4477   0.4237   0.0698   0.0195   0.4790
## 398:    0.4498   1.0164   3.4479   0.4237   0.0698   0.0195   0.4790
## 399:    0.4502   1.0162   3.4481   0.4235   0.0699   0.0196   0.4789
## 400:    0.4504   1.0161   3.4482   0.4234   0.0699   0.0196   0.4789
## 401:    0.4505   1.0161   3.4482   0.4231   0.0699   0.0196   0.4791
## 402:    0.4505   1.0161   3.4483   0.4227   0.0699   0.0196   0.4792
## 403:    0.4508   1.0160   3.4483   0.4227   0.0699   0.0196   0.4792
## 404:    0.4509   1.0160   3.4483   0.4227   0.0699   0.0196   0.4791
## 405:    0.4509   1.0160   3.4483   0.4228   0.0699   0.0196   0.4791
## 406:    0.4509   1.0160   3.4483   0.4228   0.0699   0.0196   0.4791
## 407:    0.4509   1.0159   3.4484   0.4229   0.0699   0.0196   0.4790
## 408:    0.4512   1.0160   3.4484   0.4230   0.0700   0.0196   0.4790
## 409:    0.4511   1.0160   3.4484   0.4228   0.0700   0.0196   0.4790
## 410:    0.4509   1.0160   3.4483   0.4226   0.0700   0.0196   0.4790
## 411:    0.4508   1.0160   3.4482   0.4226   0.0700   0.0196   0.4791
## 412:    0.4508   1.0161   3.4482   0.4220   0.0700   0.0196   0.4792
## 413:    0.4505   1.0162   3.4482   0.4214   0.0699   0.0196   0.4793
## 414:    0.4503   1.0163   3.4482   0.4217   0.0699   0.0196   0.4792
## 415:    0.4504   1.0163   3.4481   0.4217   0.0699   0.0196   0.4791
## 416:    0.4503   1.0164   3.4481   0.4216   0.0698   0.0196   0.4792
## 417:    0.4503   1.0164   3.4481   0.4216   0.0698   0.0196   0.4791
## 418:    0.4503   1.0164   3.4481   0.4215   0.0699   0.0196   0.4790
## 419:    0.4504   1.0164   3.4481   0.4217   0.0699   0.0197   0.4789
## 420:    0.4506   1.0165   3.4482   0.4216   0.0700   0.0196   0.4788
## 421:    0.4505   1.0165   3.4483   0.4214   0.0700   0.0196   0.4788
## 422:    0.4507   1.0163   3.4483   0.4214   0.0700   0.0196   0.4787
## 423:    0.4509   1.0163   3.4484   0.4213   0.0701   0.0196   0.4787
## 424:    0.4507   1.0162   3.4483   0.4214   0.0701   0.0196   0.4786
## 425:    0.4507   1.0163   3.4482   0.4216   0.0701   0.0196   0.4785
## 426:    0.4507   1.0164   3.4482   0.4217   0.0701   0.0196   0.4784
## 427:    0.4506   1.0165   3.4482   0.4218   0.0701   0.0196   0.4784
## 428:    0.4507   1.0165   3.4482   0.4215   0.0701   0.0196   0.4784
## 429:    0.4508   1.0165   3.4483   0.4213   0.0700   0.0196   0.4785
## 430:    0.4507   1.0165   3.4483   0.4210   0.0701   0.0196   0.4786
## 431:    0.4505   1.0165   3.4483   0.4208   0.0701   0.0196   0.4785
## 432:    0.4504   1.0166   3.4483   0.4207   0.0701   0.0196   0.4784
## 433:    0.4503   1.0167   3.4483   0.4207   0.0702   0.0196   0.4784
## 434:    0.4503   1.0166   3.4483   0.4206   0.0702   0.0196   0.4784
## 435:    0.4502   1.0166   3.4483   0.4203   0.0702   0.0196   0.4783
## 436:    0.4502   1.0166   3.4484   0.4201   0.0702   0.0196   0.4784
## 437:    0.4503   1.0166   3.4484   0.4202   0.0703   0.0196   0.4784
## 438:    0.4501   1.0167   3.4483   0.4200   0.0703   0.0195   0.4784
## 439:    0.4501   1.0168   3.4483   0.4200   0.0703   0.0195   0.4784
## 440:    0.4502   1.0168   3.4484   0.4198   0.0703   0.0195   0.4784
## 441:    0.4504   1.0168   3.4484   0.4199   0.0703   0.0195   0.4783
## 442:    0.4504   1.0169   3.4485   0.4200   0.0702   0.0195   0.4783
## 443:    0.4506   1.0169   3.4485   0.4202   0.0702   0.0195   0.4782
## 444:    0.4505   1.0170   3.4484   0.4201   0.0703   0.0195   0.4783
## 445:    0.4505   1.0170   3.4483   0.4205   0.0703   0.0194   0.4783
## 446:    0.4504   1.0171   3.4483   0.4207   0.0704   0.0194   0.4784
## 447:    0.4506   1.0171   3.4483   0.4209   0.0704   0.0194   0.4784
## 448:    0.4507   1.0171   3.4484   0.4207   0.0704   0.0194   0.4783
## 449:    0.4509   1.0171   3.4485   0.4203   0.0704   0.0194   0.4783
## 450:    0.4510   1.0171   3.4486   0.4201   0.0704   0.0194   0.4783
## 451:    0.4512   1.0170   3.4487   0.4201   0.0703   0.0194   0.4783
## 452:    0.4515   1.0170   3.4488   0.4200   0.0703   0.0194   0.4783
## 453:    0.4515   1.0169   3.4488   0.4197   0.0703   0.0194   0.4782
## 454:    0.4516   1.0170   3.4488   0.4194   0.0703   0.0194   0.4781
## 455:    0.4517   1.0170   3.4489   0.4194   0.0702   0.0194   0.4780
## 456:    0.4518   1.0169   3.4488   0.4195   0.0702   0.0194   0.4780
## 457:    0.4518   1.0169   3.4489   0.4195   0.0702   0.0194   0.4780
## 458:    0.4518   1.0169   3.4489   0.4195   0.0701   0.0194   0.4779
## 459:    0.4515   1.0170   3.4488   0.4194   0.0701   0.0194   0.4779
## 460:    0.4513   1.0171   3.4488   0.4192   0.0700   0.0194   0.4779
## 461:    0.4511   1.0172   3.4488   0.4190   0.0700   0.0194   0.4780
## 462:    0.4510   1.0173   3.4488   0.4187   0.0700   0.0194   0.4780
## 463:    0.4510   1.0173   3.4488   0.4184   0.0700   0.0194   0.4781
## 464:    0.4510   1.0174   3.4487   0.4182   0.0700   0.0194   0.4780
## 465:    0.4510   1.0173   3.4487   0.4181   0.0700   0.0194   0.4780
## 466:    0.4509   1.0173   3.4487   0.4177   0.0700   0.0194   0.4781
## 467:    0.4507   1.0172   3.4488   0.4173   0.0700   0.0194   0.4781
## 468:    0.4508   1.0172   3.4488   0.4172   0.0701   0.0194   0.4782
## 469:    0.4508   1.0174   3.4488   0.4174   0.0701   0.0194   0.4783
## 470:    0.4507   1.0174   3.4488   0.4175   0.0702   0.0193   0.4783
## 471:    0.4507   1.0174   3.4487   0.4174   0.0702   0.0193   0.4784
## 472:    0.4507   1.0174   3.4488   0.4173   0.0702   0.0193   0.4784
## 473:    0.4506   1.0174   3.4488   0.4171   0.0702   0.0193   0.4784
## 474:    0.4507   1.0174   3.4488   0.4170   0.0702   0.0193   0.4785
## 475:    0.4507   1.0175   3.4488   0.4169   0.0702   0.0193   0.4785
## 476:    0.4507   1.0175   3.4488   0.4171   0.0702   0.0193   0.4785
## 477:    0.4506   1.0175   3.4488   0.4170   0.0702   0.0193   0.4784
## 478:    0.4505   1.0175   3.4488   0.4169   0.0702   0.0193   0.4784
## 479:    0.4507   1.0174   3.4489   0.4170   0.0703   0.0193   0.4786
## 480:    0.4506   1.0174   3.4489   0.4167   0.0704   0.0193   0.4787
## 481:    0.4506   1.0175   3.4489   0.4164   0.0704   0.0193   0.4788
## 482:    0.4506   1.0175   3.4489   0.4164   0.0703   0.0193   0.4788
## 483:    0.4506   1.0174   3.4489   0.4165   0.0703   0.0193   0.4788
## 484:    0.4506   1.0173   3.4489   0.4166   0.0703   0.0193   0.4788
## 485:    0.4507   1.0174   3.4489   0.4168   0.0703   0.0193   0.4788
## 486:    0.4507   1.0174   3.4489   0.4166   0.0703   0.0193   0.4788
## 487:    0.4509   1.0174   3.4490   0.4166   0.0703   0.0193   0.4787
## 488:    0.4509   1.0173   3.4490   0.4165   0.0703   0.0193   0.4787
## 489:    0.4511   1.0173   3.4490   0.4166   0.0703   0.0193   0.4787
## 490:    0.4513   1.0173   3.4491   0.4167   0.0703   0.0193   0.4787
## 491:    0.4513   1.0173   3.4491   0.4166   0.0703   0.0193   0.4787
## 492:    0.4514   1.0173   3.4492   0.4164   0.0703   0.0193   0.4787
## 493:    0.4513   1.0173   3.4492   0.4163   0.0703   0.0193   0.4787
## 494:    0.4513   1.0173   3.4491   0.4161   0.0703   0.0193   0.4787
## 495:    0.4513   1.0173   3.4491   0.4160   0.0703   0.0193   0.4786
## 496:    0.4514   1.0173   3.4491   0.4160   0.0703   0.0193   0.4786
## 497:    0.4513   1.0173   3.4491   0.4163   0.0702   0.0193   0.4786
## 498:    0.4513   1.0173   3.4490   0.4163   0.0702   0.0193   0.4785
## 499:    0.4513   1.0174   3.4490   0.4165   0.0702   0.0193   0.4784
## 500:    0.4513   1.0173   3.4489   0.4164   0.0702   0.0193   0.4783</code></pre>
<pre><code>## Calculating covariance matrix</code></pre>
<pre><code>## [====|====|====|====|====|====|====|====|====|====</code></pre>
<pre><code>## Calculating residuals/tables
## done.
## Calculating -2LL by Gaussian quadrature (nnodes=3,nsd=1.6)</code></pre>
<pre><code>## [====|====|====|====|====|====|====|====|====|====</code></pre>
<p>And if we wanted to, we could even apply the First-Order Conditional Estimation (FOCEi) method to this model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fitF &lt;-<span class="st"> </span><span class="kw"><a href="../reference/nlmixr.html">nlmixr</a></span>(one.compartment, theo_sd, <span class="dt">est=</span><span class="st">"focei"</span>)</code></pre></div>
<pre><code>## Loading model already run (/home/matt/R/x86_64-pc-linux-gnu-library/3.5/nlmixr/nlmixr-one.compartment-theo_sd-focei-cdab62d4795084a5a33ff1bba675543c.rds)</code></pre>
<p>This example delivers a complete model fit as the <code>fit</code> object, including parameter history, a set of fixed effect estimates, and random effects for all included subjects.</p>
<p>Now back to the <code>saem</code> fit; Let’s look at the fit using nlmixr’s built-in diagnostics…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/graphics/topics/plot">plot</a></span>(fit)</code></pre></div>
<p><img src="running_nlmixr_files/figure-html/unnamed-chunk-7-1.png" width="700"><img src="running_nlmixr_files/figure-html/unnamed-chunk-7-2.png" width="700"><img src="running_nlmixr_files/figure-html/unnamed-chunk-7-3.png" width="700"><img src="running_nlmixr_files/figure-html/unnamed-chunk-7-4.png" width="700"><img src="running_nlmixr_files/figure-html/unnamed-chunk-7-5.png" width="700"><img src="running_nlmixr_files/figure-html/unnamed-chunk-7-6.png" width="700"><img src="running_nlmixr_files/figure-html/unnamed-chunk-7-7.png" width="700"><img src="running_nlmixr_files/figure-html/unnamed-chunk-7-8.png" width="700"><img src="running_nlmixr_files/figure-html/unnamed-chunk-7-9.png" width="700"><img src="running_nlmixr_files/figure-html/unnamed-chunk-7-10.png" width="700"><img src="running_nlmixr_files/figure-html/unnamed-chunk-7-11.png" width="700"><img src="running_nlmixr_files/figure-html/unnamed-chunk-7-12.png" width="700"><img src="running_nlmixr_files/figure-html/unnamed-chunk-7-13.png" width="700"><img src="running_nlmixr_files/figure-html/unnamed-chunk-7-14.png" width="700"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/print">print</a></span>(fit)</code></pre></div>
<pre><code>## ── nlmixr SAEM(ODE); OBJF by Gaussian Quadrature (n.nodes=3, n.sd=1.6) fit  
##                OBJF      AIC      BIC Log-likelihood Condition Number
## gauss3_1.6 122.9719 379.5717 399.7513      -182.7858         18.16274
## 
## ── Time (sec; $time): ───────────────────────────────────────────────────── 
##          saem    setup table covariance logLik    other
## elapsed 8.986 0.277117 0.007      0.007  0.031 0.235883
## 
## ── Population Parameters ($parFixed or $parFixedDf): ────────────────────── 
##         Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%)
## tka        Log Ka 0.451  0.196 43.5       1.57 (1.07, 2.31)     71.9
## tcl        Log Cl  1.02 0.0836 8.22       2.77 (2.35, 3.26)     27.0
## tv          Log V  3.45 0.0469 1.36       31.5 (28.7, 34.5)     14.0
## add.err           0.692                               0.692         
##         Shrink(SD)%
## tka         0.411% 
## tcl          3.36% 
## tv           10.0% 
## add.err             
## 
##   Covariance Type ($covMethod): linFim
##   No correlations in between subject variability (BSV) matrix
##   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs) 
##   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink 
## 
## ── Fit Data (object is a modified tibble): ──────────────────────────────── 
## # A tibble: 132 x 18
##   ID     TIME    DV  EVID  PRED    RES IPRED   IRES  IWRES eta.ka eta.cl
##   &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1 1     0      0.74     0  0     0.74   0     0.74   1.07   0.105 -0.487
## 2 1     0.25   2.84     0  3.26 -0.423  3.86 -1.02  -1.48   0.105 -0.487
## 3 1     0.570  6.57     0  5.84  0.725  6.81 -0.235 -0.340  0.105 -0.487
## # … with 129 more rows, and 7 more variables: eta.v &lt;dbl&gt;, ka &lt;dbl&gt;,
## #   cl &lt;dbl&gt;, v &lt;dbl&gt;, cp &lt;dbl&gt;, depot &lt;dbl&gt;, center &lt;dbl&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit<span class="op">$</span>eta</code></pre></div>
<table class="table huxtable">
<col>
<col>
<col>
<col>
<tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0.4pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">ID</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">eta.ka</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">eta.cl</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">eta.v</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">1</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.105 </td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">-0.487 </td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">-0.08   </td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">2</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.221 </td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.144 </td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt;">0.0206 </td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">3</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.368 </td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.0311</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.058  </td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">4</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">-0.277 </td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">-0.015 </td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt;">-0.00723</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">5</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">-0.0458</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">-0.155 </td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">-0.142  </td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">6</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">-0.382 </td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.367 </td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt;">0.203  </td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">7</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">-0.791 </td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.16  </td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.0466 </td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">8</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">-0.181 </td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.168 </td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt;">0.0958 </td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">9</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">1.42  </td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.0423</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.0121 </td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">10</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">-0.738 </td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">-0.391 </td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt;">-0.17   </td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">11</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.79  </td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.281 </td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.146  </td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">12</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">-0.527 </td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">-0.126 </td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">-0.198  </td>
</tr>
</table>
<p>Default trace plots can be generated using:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/traceplot.html">traceplot</a></span>(fit)</code></pre></div>
<p><img src="running_nlmixr_files/figure-html/unnamed-chunk-10-1.png" width="700"></p>
<p>but with a little more work, we can get a nicer set of iteration trace plots (“wriggly worms”)…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">iter &lt;-<span class="st"> </span>fit<span class="op">$</span>par.hist.stacked
iter<span class="op">$</span>Parameter[iter<span class="op">$</span>par<span class="op">==</span><span class="st">"add.err"</span>] &lt;-<span class="st"> "Additive error"</span>
iter<span class="op">$</span>Parameter[iter<span class="op">$</span>par<span class="op">==</span><span class="st">"eta.cl"</span>]  &lt;-<span class="st"> "IIV CL/F"</span>
iter<span class="op">$</span>Parameter[iter<span class="op">$</span>par<span class="op">==</span><span class="st">"eta.v"</span>]   &lt;-<span class="st"> "IIV V/F"</span>
iter<span class="op">$</span>Parameter[iter<span class="op">$</span>par<span class="op">==</span><span class="st">"eta.ka"</span>]  &lt;-<span class="st"> "IIV ka"</span>
iter<span class="op">$</span>Parameter[iter<span class="op">$</span>par<span class="op">==</span><span class="st">"tcl"</span>]     &lt;-<span class="st"> "log(CL/F)"</span>
iter<span class="op">$</span>Parameter[iter<span class="op">$</span>par<span class="op">==</span><span class="st">"tv"</span>]      &lt;-<span class="st"> "log(V/F)"</span>
iter<span class="op">$</span>Parameter[iter<span class="op">$</span>par<span class="op">==</span><span class="st">"tka"</span>]     &lt;-<span class="st"> "log(ka)"</span>
iter<span class="op">$</span>Parameter &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/factor">ordered</a></span>(iter<span class="op">$</span>Parameter, <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">"log(CL/F)"</span>, <span class="st">"log(V/F)"</span>, <span class="st">"log(ka)"</span>,
                                            <span class="st">"IIV CL/F"</span>, <span class="st">"IIV V/F"</span>, <span class="st">"IIV ka"</span>,
                                            <span class="st">"Additive error"</span>))

<span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/ggplot">ggplot</a></span>(iter, <span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/aes">aes</a></span>(iter, val)) <span class="op">+</span>
<span class="st">  </span><span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/geom_path">geom_line</a></span>(<span class="dt">col=</span><span class="st">"red"</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/scale_continuous">scale_x_continuous</a></span>(<span class="st">"Iteration"</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/scale_continuous">scale_y_continuous</a></span>(<span class="st">"Value"</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/facet_wrap">facet_wrap</a></span>(<span class="op">~</span><span class="st"> </span>Parameter, <span class="dt">scales=</span><span class="st">"free_y"</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/labs">labs</a></span>(<span class="dt">title=</span><span class="st">"Theophylline single-dose"</span>, <span class="dt">subtitle=</span><span class="st">"Parameter estimation iterations"</span>)</code></pre></div>
<p><img src="running_nlmixr_files/figure-html/unnamed-chunk-11-1.png" width="700"></p>
<p>… and some random-effects histograms…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">etas &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/data.frame">data.frame</a></span>(<span class="dt">eta =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(fit<span class="op">$</span>eta<span class="op">$</span>eta.ka, fit<span class="op">$</span>eta<span class="op">$</span>eta.cl, fit<span class="op">$</span>eta<span class="op">$</span>eta.v),
                   <span class="dt">lab =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/rep">rep</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">"eta(ka)"</span>, <span class="st">"eta(CL/F)"</span>, <span class="st">"eta(V/F)"</span>), <span class="dt">each=</span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/nrow">nrow</a></span>(fit<span class="op">$</span>eta)))
etas<span class="op">$</span>lab &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/factor">ordered</a></span>(etas<span class="op">$</span>lab, <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">"eta(CL/F)"</span>,<span class="st">"eta(V/F)"</span>,<span class="st">"eta(ka)"</span>))

<span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/ggplot">ggplot</a></span>(etas, <span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/aes">aes</a></span>(eta)) <span class="op">+</span>
<span class="st">  </span><span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/geom_histogram">geom_histogram</a></span>(<span class="dt">fill=</span><span class="st">"red"</span>, <span class="dt">col=</span><span class="st">"white"</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/geom_abline">geom_vline</a></span>(<span class="dt">xintercept=</span><span class="dv">0</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/scale_continuous">scale_x_continuous</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/expression">expression</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/paste">paste</a></span>(eta))) <span class="op">+</span>
<span class="st">  </span><span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/scale_continuous">scale_y_continuous</a></span>(<span class="st">"Count"</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/facet_grid">facet_grid</a></span>(<span class="op">~</span><span class="st"> </span>lab) <span class="op">+</span>
<span class="st">  </span><span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/coord_cartesian">coord_cartesian</a></span>(<span class="dt">xlim=</span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="op">-</span><span class="fl">1.75</span>,<span class="fl">1.75</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw"><a href="https://www.rdocumentation.org/packages/ggplot2/topics/labs">labs</a></span>(<span class="dt">title=</span><span class="st">"Theophylline single-dose"</span>, <span class="dt">subtitle=</span><span class="st">"IIV distributions"</span>)</code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="running_nlmixr_files/figure-html/unnamed-chunk-12-1.png" width="700"></p>
<div id="xpose" class="section level2">
<h2 class="hasAnchor">
<a href="#xpose" class="anchor"></a>xpose</h2>
<p>This is all very nice. But what we really want is a complete suite of model diagnostic tools, like those available in <a href="https://github.com/UUPharmacometrics/xpose">xpose</a>, right?</p>
<p>Restart R, and install xpose from CRAN, if you haven’t already…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## install.packages("xpose")
<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(xpose)</code></pre></div>
<pre><code>## 
## Attaching package: 'xpose'</code></pre>
<pre><code>## The following object is masked from 'package:nlmixr':
## 
##     vpc</code></pre>
<pre><code>## The following object is masked from 'package:stats':
## 
##     filter</code></pre>
<p>Now install the extension for nlmixr:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">xpdbLoc &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/file.path">file.path</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/system.file">system.file</a></span>(<span class="dt">package=</span><span class="st">"nlmixr"</span>), <span class="st">"xpdb.rds"</span>);
<span class="cf">if</span> (<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/files">file.exists</a></span>(xpdbLoc)){
    <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/load">load</a></span>(xpdbLoc);
} <span class="cf">else</span> {
    ## devtools::install_github("nlmixrdevelopment/xpose.nlmixr")
    <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(xpose.nlmixr)
    xp &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/xpose.nlmixr/topics/xpose_data_nlmixr">xpose_data_nlmixr</a></span>(fit);
    <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/save">save</a></span>(xp, <span class="dt">file=</span>xpdbLoc)
}</code></pre></div>
<pre><code>## 
## Attaching package: 'xpose.nlmixr'</code></pre>
<pre><code>## The following object is masked from 'package:nlmixr':
## 
##     vpc</code></pre>
<pre><code>## Calculating residuals/tables</code></pre>
<pre><code>## done.</code></pre>
<pre><code>## Warning in xpose_data_nlmixr(fit): Added CWRES to fit (using
## nlmixr::addCwres)</code></pre>
<p>… and convert your nlmixr fit object into an xpose fit object.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/xpose/topics/dv_vs_pred">dv_vs_pred</a></span>(xp)</code></pre></div>
<p><img src="running_nlmixr_files/figure-html/unnamed-chunk-15-1.png" width="700"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/xpose/topics/dv_vs_pred">dv_vs_ipred</a></span>(xp)</code></pre></div>
<p><img src="running_nlmixr_files/figure-html/unnamed-chunk-16-1.png" width="700"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/xpose/topics/dv_vs_pred">dv_vs_pred</a></span>(xp)</code></pre></div>
<p><img src="running_nlmixr_files/figure-html/unnamed-chunk-17-1.png" width="700"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/xpose/topics/res_vs_pred">absval_res_vs_pred</a></span>(xp, <span class="dt">res=</span><span class="st">"IWRES"</span>)</code></pre></div>
<p><img src="running_nlmixr_files/figure-html/unnamed-chunk-18-1.png" width="700"> We can also replicate some of nlmixr’s internal plots…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/xpose/topics/ind_plots">ind_plots</a></span>(xp, <span class="dt">res=</span><span class="st">"IWRES"</span>)</code></pre></div>
<p><img src="running_nlmixr_files/figure-html/unnamed-chunk-19-1.png" width="700"><img src="running_nlmixr_files/figure-html/unnamed-chunk-19-2.png" width="700"></p>
<p>For more information about using xpose, see the Uppsala pharmacometrics group’s comprehensive site <a href="https://uupharmacometrics.github.io/xpose/">here</a>.</p>
</div>
</div>
<div id="the-ui" class="section level1">
<h1 class="hasAnchor">
<a href="#the-ui" class="anchor"></a>The UI</h1>
<p>The nlmixr modeling dialect, inspired by R and NONMEM, can be used to fit models using all current and future estimation alogorithms within nlmixr. Using these widely-used tools as inspiration has the advantage of delivering a model specification syntax taht is instantly familira to the majority of analysts working in pharmacometrics and related fields.</p>
<div id="overall-model-structure" class="section level2">
<h2 class="hasAnchor">
<a href="#overall-model-structure" class="anchor"></a>Overall model structure</h2>
<p>Model specifications for nlmixr are written using functions containing <code>ini</code> and <code>model</code> blocks. These functions can be called anything, but must contain these two components. Let’s look at a very simple one-compartment model with no covariates.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f &lt;-<span class="st"> </span><span class="cf">function</span>() {
    <span class="kw"><a href="../reference/ini.html">ini</a></span>({   <span class="co"># Initial conditions/variables</span>
            <span class="co"># are specified here</span>
    })
    <span class="kw"><a href="../reference/model.html">model</a></span>({ <span class="co"># The model is specified</span>
            <span class="co"># here</span>
    })
}</code></pre></div>
<div id="the-ini-block" class="section level3">
<h3 class="hasAnchor">
<a href="#the-ini-block" class="anchor"></a>The ini block</h3>
<p>The <code>ini</code> block specifies initial conditions, including initial estimates and boundaries for those algorithms which support them (currently, the built-in <code>nlme</code> and <code>saem</code> methods do not). Nomenclature is similar to that used in NONMEM, Monolix and other similar packages. In the NONMEM world, the <code>ini</code> block is analogous to <code>$THETA</code>, <code>$OMEGA</code> and <code>$SIGMA</code> blocks.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f &lt;-<span class="st"> </span><span class="cf">function</span>(){ <span class="co"># Note that arguments to the function are currently</span>
                 <span class="co"># ignored by nlmixr</span>
    <span class="kw"><a href="../reference/ini.html">ini</a></span>({
        <span class="co"># Initial conditions for population parameters (sometimes</span>
        <span class="co"># called THETA parameters) are defined by either '&lt;-' or '='</span>
        lCl &lt;-<span class="st"> </span><span class="fl">1.6</span>      <span class="co"># log Cl (L/hr)</span>
        
        <span class="co"># Note that simple expressions that evaluate to a number are</span>
        <span class="co"># OK for defining initial conditions (like in R)</span>
        lVc =<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Log">log</a></span>(<span class="dv">90</span>)  <span class="co"># log V (L)</span>
        
        ## Also, note that a comment on a parameter is captured as a parameter label
        lKa &lt;-<span class="st"> </span><span class="dv">1</span>       <span class="co"># log Ka (1/hr)</span>
        
        <span class="co"># Bounds may be specified by c(lower, est, upper), like NONMEM:</span>
        <span class="co"># Residuals errors are assumed to be population parameters</span>
        prop.err &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="dv">0</span>, <span class="fl">0.2</span>, <span class="dv">1</span>)
        
        <span class="co"># IIV terms will be discussed in the next example</span>
    })
    
    <span class="co"># The model block will be discussed later</span>
    <span class="kw"><a href="../reference/model.html">model</a></span>({})
}</code></pre></div>
<p>As shown in the above example:</p>
<ul>
<li>Simple parameter values are specified using an R-compatible assignment</li>
<li>Boundaries my be specified by <code><a href="https://www.rdocumentation.org/packages/base/topics/c">c(lower, est, upper)</a></code>.</li>
<li>Like NONMEM, <code><a href="https://www.rdocumentation.org/packages/base/topics/c">c(lower,est)</a></code> is equivalent to <code><a href="https://www.rdocumentation.org/packages/base/topics/c">c(lower,est,Inf)</a></code>
</li>
<li>Also like NONMEM, <code><a href="https://www.rdocumentation.org/packages/base/topics/c">c(est)</a></code> does not specify a lower bound, and is equivalent to specifying the parameter without using R’s <code><a href="https://www.rdocumentation.org/packages/base/topics/c">c()</a></code> function.</li>
</ul>
<p>These parameters can be named using almost any R-compatible name. Please note that:</p>
<ul>
<li>Residual error estimates should be coded as population estimates (i.e. using <code>=</code> or <code>&lt;-</code>, not <code>~</code>).</li>
<li>Variable names that start with <code>_</code> are not supported. Note that R does not allow variable starting with <code>_</code> to be assigned without quoting them.</li>
<li>Naming variables that start with <code>rx_</code> or <code>nlmixr_</code> is not allowed, since RxODE and nlmixr use these prefixes internally for certain estimation routines and for calculating residuals.</li>
<li>Variable names are case-sensitive, just like they are in R. <code>CL</code> is not the same as <code>Cl</code>.</li>
</ul>
<p>In mixture models, multivariate normal individual deviations from the normal population and parameters are estimated (in NONMEM these are called “ETA” parameters). Additionally, the variance/covariance matrix of these deviations are is also estimated (in NONMEM this is the “OMEGA” matrix). These also take initial estimates. In nlmixr, these are specified by the <code>~</code> operator. This that is typically used in statistics R for “modeled by”, and was chosen to distinguish these estimates from the population and residual error parameters.</p>
<p>Continuing from the prior example, we can annotate the estimates for the between-subject error distribution…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f &lt;-<span class="st"> </span><span class="cf">function</span>(){
    <span class="kw"><a href="../reference/ini.html">ini</a></span>({
        lCl &lt;-<span class="st"> </span><span class="fl">1.6</span>      <span class="co"># log Cl (L/hr)</span>
        lVc =<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Log">log</a></span>(<span class="dv">90</span>)   <span class="co"># log V (L)</span>
        lKa &lt;-<span class="st"> </span><span class="dv">1</span>        <span class="co"># log Ka (1/hr)</span>
        prop.err &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="dv">0</span>, <span class="fl">0.2</span>, <span class="dv">1</span>)
        
        <span class="co"># Initial estimate for ka IIV variance</span>
        <span class="co"># Labels work for single parameters</span>
        eta.ka <span class="op">~</span><span class="st"> </span><span class="fl">0.1</span>    ## BSV Ka

        <span class="co"># For correlated parameters, you specify the names of each</span>
        <span class="co"># correlated parameter separated by a addition operator `+`</span>
        <span class="co"># and the left handed side specifies the lower triangular</span>
        <span class="co"># matrix initial of the covariance matrix.</span>
        eta.cl <span class="op">+</span><span class="st"> </span>eta.vc <span class="op">~</span><span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="fl">0.1</span>,
                            <span class="fl">0.005</span>, <span class="fl">0.1</span>)
                            
        <span class="co"># Note that labels do not currently work for correlated</span>
        <span class="co"># parameters.  Also, do not put comments inside the lower</span>
        <span class="co"># triangular matrix as this will currently break the model.</span>
    })
    
    <span class="co"># The model block will be discussed later</span>
    <span class="kw"><a href="../reference/model.html">model</a></span>({})
}</code></pre></div>
<p>As shown in the above example:</p>
<ul>
<li>Simple variances are specified by the variable name and the estimate separated by <code>~</code>.</li>
<li>Correlated parameters are specified by the sum of the variable labels and then the lower triangular matrix of the covariance is specified on the left handed side of the equation. This is also separated by <code>~</code>.</li>
<li>The initial estimates are specified on the variance scale, and in analogy with NONMEM, the square roots of the diagonal elements correspond to coefficients of variation when used in the exponential IIV implementation.</li>
</ul>
<p>Currently, comments inside the lower triangular matrix are not allowed.</p>
</div>
<div id="the-model-block" class="section level3">
<h3 class="hasAnchor">
<a href="#the-model-block" class="anchor"></a>The model block</h3>
<p>The <code>model</code> block specifies the model, and is analogous to the <code>$PK</code>, <code>$PRED</code> and <code>$ERROR</code> blocks in NONMEM.</p>
<p>Once the initialization block has been defined, you can define a model in terms of the variables defined in the <code>ini</code> block. You can also mix RxODE blocks into the model if needed.</p>
<p>The current method of defining a nlmixr model is to specify the parameters, and then any required RxODE lines. Continuing the annotated example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f &lt;-<span class="st"> </span><span class="cf">function</span>(){
    <span class="kw"><a href="../reference/ini.html">ini</a></span>({
        lCl &lt;-<span class="st"> </span><span class="fl">1.6</span>       <span class="co"># log Cl (L/hr)</span>
        lVc &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Log">log</a></span>(<span class="dv">90</span>)   <span class="co"># log Vc (L)</span>
        lKA &lt;-<span class="st"> </span><span class="fl">0.1</span>       <span class="co"># log Ka (1/hr)</span>
        prop.err &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="dv">0</span>, <span class="fl">0.2</span>, <span class="dv">1</span>)
        
        eta.Cl <span class="op">~</span><span class="st"> </span><span class="fl">0.1</span>     <span class="co"># BSV Cl</span>
        eta.Vc <span class="op">~</span><span class="st"> </span><span class="fl">0.1</span>     <span class="co"># BSV Vc</span>
        eta.KA <span class="op">~</span><span class="st"> </span><span class="fl">0.1</span>     <span class="co"># BSV Ka</span>
    })
    <span class="kw"><a href="../reference/model.html">model</a></span>({
        <span class="co"># Parameters are defined in terms of the previously-defined</span>
        <span class="co"># parameter names:</span>
        Cl &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Log">exp</a></span>(lCl <span class="op">+</span><span class="st"> </span>eta.Cl)
        Vc =<span class="st">  </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Log">exp</a></span>(lVc <span class="op">+</span><span class="st"> </span>eta.Vc)
        KA &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Log">exp</a></span>(lKA <span class="op">+</span><span class="st"> </span>eta.KA)
        
        <span class="co"># Next, the differential equations are defined:</span>
        kel &lt;-<span class="st"> </span>Cl <span class="op">/</span><span class="st"> </span>Vc;
        
        d<span class="op">/</span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/TDist">dt</a></span>(depot)  =<span class="st"> </span><span class="op">-</span>KA<span class="op">*</span>depot;
        d<span class="op">/</span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/TDist">dt</a></span>(centr)  =<span class="st">  </span>KA<span class="op">*</span>depot<span class="op">-</span>kel<span class="op">*</span>centr;
        
        <span class="co"># And the concentration is then calculated</span>
        cp =<span class="st"> </span>centr <span class="op">/</span><span class="st"> </span>Vc;
        <span class="co"># Finally, we specify that the plasma concentration follows</span>
        <span class="co"># a proportional error distribution (estimated by the parameter </span>
        <span class="co"># prop.err)</span>
        cp <span class="op">~</span><span class="st"> </span><span class="kw">prop</span>(prop.err)
    })

}</code></pre></div>
<p>A few points to note:</p>
<ul>
<li>Parameters are defined before the differential equations. Currently directly defining the differential equations in terms of the population parameters is not supported.</li>
<li>The differential equations, parameters and error terms are in a single block, instead of multiple sections.</li>
<li>Additionally state names, calculated variables, also cannot start with either <code>rx_</code> or <code>nlmixr_</code> since these are used internally in some estimation routines.</li>
<li>Errors are specified using the tilde, <code>~</code>. Currently you can use either <code>add(parameter)</code> for additive error, <code>prop(parameter)</code> for proportional error or <code>add(parameter1) + prop(parameter2)</code> for combined additive and proportional error. You can also specify <code><a href="https://www.rdocumentation.org/packages/base/topics/norm">norm(parameter)</a></code> for additive error, since it follows a normal distribution.</li>
<li>Some routines, like <code>saem</code>, require parameters expressed in terms of <code>Pop.Parameter + Individual.Deviation.Parameter +   Covariate*Covariate.Parameter</code>. The order of these parameters does not matter. This is similar to NONMEM’s mu-referencing, though not as restrictive. This means that for <code>saem</code>, a parameterization of the form <code>Cl &lt;- Cl*exp(eta.Cl)</code> is not allowed.</li>
<li>The type of parameter in the model is determined by the <code>ini</code> block; covariates used in the model are not included in the <code>ini</code> block. These variables need to be present in the modeling dataset for the model to run.</li>
</ul>
</div>
</div>
<div id="running-models" class="section level2">
<h2 class="hasAnchor">
<a href="#running-models" class="anchor"></a>Running models</h2>
<p>Models can be fitted several ways, including via the [magrittr] forward-pipe operator.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw"><a href="../reference/nlmixr.html">nlmixr</a></span>(one.compartment) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/saem.fit.html">saem.fit</a></span>(<span class="dt">data=</span>theo_sd)</code></pre></div>
<pre><code>## Compiling RxODE equations...done.</code></pre>
<pre><code>## 1:    0.2288   0.9677   3.4737   0.5700   0.2850   0.0950   4.5245
## 2:    0.3623   0.9821   3.5318   0.5415   0.2707   0.0902   1.8046
## 3:    0.4864   0.9181   3.4872   0.5144   0.2572   0.0857   0.9422
## 4:    0.4480   0.9416   3.4843   0.4887   0.2444   0.0815   0.6940
## 5:    0.4844   0.9591   3.4754   0.4643   0.2321   0.0774   0.6019
## 6:    0.4986   0.9687   3.4752   0.4411   0.2205   0.0735   0.5056
## 7:    0.4577   0.9953   3.4634   0.4251   0.2095   0.0698   0.5076
## 8:    0.4473   0.9911   3.4666   0.4039   0.1990   0.0663   0.5155
## 9:    0.4188   0.9755   3.4615   0.3837   0.1891   0.0630   0.5210
## 10:    0.4349   0.9798   3.4521   0.4305   0.1796   0.0599   0.4901
## 11:    0.4537   0.9976   3.4548   0.4089   0.1706   0.0569   0.4911
## 12:    0.4421   1.0104   3.4458   0.3885   0.1621   0.0540   0.4628
## 13:    0.3941   1.0454   3.4243   0.3691   0.1540   0.0513   0.4783
## 14:    0.4189   1.0204   3.4380   0.4545   0.1463   0.0488   0.5002
## 15:    0.4506   1.0202   3.4468   0.4318   0.1390   0.0463   0.4889
## 16:    0.4552   1.0112   3.4524   0.4209   0.1320   0.0440   0.5038
## 17:    0.4542   1.0115   3.4558   0.4164   0.1254   0.0418   0.4658
## 18:    0.4820   0.9828   3.4521   0.4451   0.1192   0.0397   0.5021
## 19:    0.4339   0.9924   3.4505   0.4228   0.1132   0.0377   0.4914
## 20:    0.4527   1.0041   3.4472   0.4037   0.1075   0.0358   0.4928
## 21:    0.4404   1.0079   3.4558   0.3885   0.1022   0.0341   0.4739
## 22:    0.4625   1.0138   3.4599   0.4469   0.0971   0.0324   0.4520
## 23:    0.5104   1.0181   3.4648   0.4535   0.0922   0.0307   0.4667
## 24:    0.5050   1.0228   3.4659   0.4308   0.0876   0.0292   0.4543
## 25:    0.4633   0.9967   3.4608   0.4093   0.0861   0.0277   0.4789
## 26:    0.4183   1.0293   3.4345   0.4183   0.0818   0.0264   0.4644
## 27:    0.4126   1.0361   3.4357   0.3973   0.0777   0.0250   0.4941
## 28:    0.4592   1.0181   3.4429   0.3775   0.0738   0.0238   0.4538
## 29:    0.4413   1.0248   3.4369   0.3586   0.0701   0.0226   0.4801
## 30:    0.4506   1.0195   3.4440   0.3689   0.0672   0.0215   0.4824
## 31:    0.4049   1.0069   3.4520   0.3505   0.0768   0.0204   0.4778
## 32:    0.4292   0.9864   3.4607   0.3939   0.0729   0.0205   0.4702
## 33:    0.4417   1.0151   3.4477   0.4332   0.0693   0.0195   0.4917
## 34:    0.4597   1.0252   3.4485   0.4238   0.0658   0.0185   0.4909
## 35:    0.4485   0.9940   3.4511   0.4026   0.0637   0.0176   0.4766
## 36:    0.4405   1.0103   3.4488   0.3825   0.0658   0.0167   0.4873
## 37:    0.4408   1.0163   3.4572   0.3731   0.0707   0.0195   0.4872
## 38:    0.5014   1.0088   3.4476   0.4544   0.0752   0.0185   0.4844
## 39:    0.5031   0.9852   3.4647   0.4819   0.0715   0.0245   0.4632
## 40:    0.4910   0.9905   3.4762   0.4578   0.0679   0.0272   0.4737
## 41:    0.4276   0.9901   3.4569   0.4349   0.0645   0.0259   0.4968
## 42:    0.4696   1.0088   3.4529   0.4236   0.0656   0.0246   0.4457
## 43:    0.4296   1.0293   3.4341   0.4025   0.0641   0.0233   0.4549
## 44:    0.4268   1.0334   3.4423   0.3823   0.0609   0.0237   0.4758
## 45:    0.4435   1.0397   3.4447   0.4115   0.0585   0.0265   0.4409
## 46:    0.4406   1.0217   3.4500   0.3910   0.0765   0.0252   0.4533
## 47:    0.4454   1.0224   3.4450   0.3841   0.0727   0.0239   0.4644
## 48:    0.4597   1.0215   3.4499   0.4516   0.0691   0.0238   0.4763
## 49:    0.4512   1.0173   3.4484   0.4290   0.0668   0.0239   0.4950
## 50:    0.4538   0.9948   3.4407   0.4076   0.0767   0.0227   0.5089
## 51:    0.4708   1.0340   3.4357   0.4159   0.0729   0.0216   0.4933
## 52:    0.5150   1.0202   3.4583   0.4959   0.0692   0.0205   0.4824
## 53:    0.5019   1.0156   3.4502   0.4711   0.0658   0.0195   0.5123
## 54:    0.4544   1.0083   3.4541   0.4476   0.0654   0.0188   0.5106
## 55:    0.4427   1.0017   3.4534   0.4252   0.0705   0.0191   0.4871
## 56:    0.4411   0.9917   3.4486   0.4039   0.0670   0.0214   0.4881
## 57:    0.4808   1.0063   3.4621   0.3957   0.0668   0.0203   0.4932
## 58:    0.5100   1.0050   3.4567   0.4291   0.0677   0.0193   0.4939
## 59:    0.5064   0.9712   3.4642   0.4676   0.0888   0.0183   0.5044
## 60:    0.4913   0.9699   3.4635   0.4897   0.0844   0.0184   0.5282
## 61:    0.5047   0.9892   3.4614   0.5644   0.0801   0.0187   0.5103
## 62:    0.4536   1.0146   3.4580   0.5362   0.0826   0.0193   0.5128
## 63:    0.4776   1.0017   3.4530   0.5094   0.0915   0.0184   0.4863
## 64:    0.4550   1.0007   3.4565   0.4839   0.0903   0.0176   0.4998
## 65:    0.4857   1.0002   3.4422   0.4597   0.0874   0.0193   0.4952
## 66:    0.4478   1.0116   3.4506   0.4368   0.0878   0.0189   0.4872
## 67:    0.4560   0.9978   3.4400   0.4149   0.0834   0.0198   0.4768
## 68:    0.4015   1.0105   3.4500   0.3942   0.0792   0.0188   0.5248
## 69:    0.4199   1.0082   3.4475   0.4043   0.0752   0.0200   0.5082
## 70:    0.4253   1.0065   3.4493   0.4755   0.0731   0.0205   0.5055
## 71:    0.4117   1.0205   3.4353   0.4518   0.0709   0.0194   0.5004
## 72:    0.4360   0.9896   3.4507   0.4292   0.0794   0.0185   0.4803
## 73:    0.4627   1.0107   3.4625   0.4077   0.0755   0.0175   0.5032
## 74:    0.4423   0.9902   3.4615   0.3951   0.0717   0.0167   0.5050
## 75:    0.4804   0.9934   3.4805   0.3992   0.0838   0.0198   0.4787
## 76:    0.5158   1.0021   3.4882   0.4126   0.0796   0.0189   0.5092
## 77:    0.5218   0.9735   3.4803   0.4015   0.0756   0.0212   0.4962
## 78:    0.4955   0.9901   3.4782   0.4149   0.0723   0.0212   0.4968
## 79:    0.4812   1.0022   3.4688   0.4388   0.0687   0.0226   0.5138
## 80:    0.4961   0.9871   3.4663   0.5095   0.0663   0.0231   0.5008
## 81:    0.5070   1.0060   3.4671   0.4841   0.0629   0.0220   0.4849
## 82:    0.4839   0.9860   3.4730   0.4599   0.0598   0.0277   0.4823
## 83:    0.4757   1.0172   3.4654   0.4473   0.0568   0.0263   0.4652
## 84:    0.4435   0.9975   3.4540   0.4364   0.0540   0.0261   0.4610
## 85:    0.4664   1.0161   3.4677   0.4214   0.0540   0.0248   0.4924
## 86:    0.4662   1.0089   3.4598   0.4003   0.0599   0.0275   0.4604
## 87:    0.4415   1.0119   3.4497   0.3899   0.0569   0.0262   0.4832
## 88:    0.3796   1.0086   3.4436   0.4004   0.0589   0.0249   0.4865
## 89:    0.4269   1.0175   3.4436   0.3804   0.0593   0.0236   0.5350
## 90:    0.4326   1.0242   3.4437   0.4088   0.0563   0.0224   0.5157
## 91:    0.4446   1.0109   3.4282   0.4562   0.0597   0.0216   0.4853
## 92:    0.4320   1.0268   3.4386   0.5057   0.0691   0.0236   0.4781
## 93:    0.3564   1.0149   3.4338   0.4804   0.0698   0.0224   0.5011
## 94:    0.3878   1.0151   3.4224   0.4563   0.0727   0.0213   0.5119
## 95:    0.4563   1.0220   3.4455   0.5434   0.0709   0.0202   0.5027
## 96:    0.4575   1.0088   3.4446   0.5162   0.0673   0.0206   0.4731
## 97:    0.4498   1.0277   3.4474   0.4904   0.0640   0.0197   0.4830
## 98:    0.4713   1.0243   3.4547   0.4659   0.0617   0.0187   0.4752
## 99:    0.4413   1.0028   3.4478   0.4426   0.0587   0.0194   0.4663
## 100:    0.4279   1.0081   3.4471   0.4205   0.0648   0.0213   0.4570
## 101:    0.4195   1.0062   3.4350   0.4386   0.0788   0.0202   0.4638
## 102:    0.4093   1.0121   3.4290   0.4565   0.0749   0.0192   0.4679
## 103:    0.4730   1.0048   3.4494   0.4635   0.0711   0.0201   0.4593
## 104:    0.4535   1.0068   3.4564   0.4917   0.0693   0.0193   0.4936
## 105:    0.4404   1.0082   3.4391   0.5036   0.0828   0.0183   0.5014
## 106:    0.4470   1.0029   3.4488   0.4785   0.0839   0.0174   0.4972
## 107:    0.4493   1.0090   3.4480   0.4990   0.0820   0.0166   0.4727
## 108:    0.4533   1.0076   3.4550   0.4741   0.0779   0.0178   0.4784
## 109:    0.4513   1.0176   3.4609   0.4504   0.0740   0.0176   0.4651
## 110:    0.4804   0.9923   3.4544   0.4616   0.0703   0.0187   0.4615
## 111:    0.4768   0.9979   3.4601   0.4385   0.0801   0.0178   0.4392
## 112:    0.4809   0.9864   3.4540   0.4495   0.0761   0.0187   0.4452
## 113:    0.4422   1.0386   3.4474   0.4592   0.0723   0.0182   0.4465
## 114:    0.4311   1.0411   3.4368   0.4363   0.0771   0.0190   0.4466
## 115:    0.4261   1.0006   3.4460   0.4145   0.0733   0.0197   0.4811
## 116:    0.4618   1.0050   3.4459   0.4178   0.0696   0.0190   0.4804
## 117:    0.4243   1.0276   3.4502   0.3969   0.0758   0.0181   0.4830
## 118:    0.4661   1.0209   3.4537   0.3771   0.0798   0.0177   0.4902
## 119:    0.4684   1.0132   3.4548   0.4747   0.0838   0.0220   0.5065
## 120:    0.4260   1.0016   3.4485   0.4611   0.0796   0.0209   0.4749
## 121:    0.4415   1.0288   3.4409   0.4380   0.0756   0.0199   0.4814
## 122:    0.4389   1.0077   3.4469   0.4161   0.0719   0.0189   0.4544
## 123:    0.4391   1.0456   3.4443   0.4249   0.0683   0.0203   0.4614
## 124:    0.4663   1.0506   3.4504   0.4291   0.0669   0.0197   0.4463
## 125:    0.4714   1.0387   3.4485   0.4077   0.0829   0.0188   0.4568
## 126:    0.4426   1.0411   3.4412   0.4396   0.0891   0.0189   0.4532
## 127:    0.4472   1.0047   3.4338   0.4235   0.0859   0.0206   0.4881
## 128:    0.4413   1.0274   3.4457   0.4504   0.0817   0.0258   0.5163
## 129:    0.4669   1.0151   3.4652   0.4828   0.0776   0.0245   0.4812
## 130:    0.5358   1.0291   3.4502   0.5114   0.0737   0.0233   0.4844
## 131:    0.4486   1.0021   3.4407   0.4858   0.0757   0.0223   0.4845
## 132:    0.4105   1.0228   3.4263   0.4615   0.0845   0.0212   0.5082
## 133:    0.4199   1.0085   3.4401   0.4384   0.0803   0.0201   0.5018
## 134:    0.4689   1.0094   3.4565   0.4267   0.0763   0.0216   0.4707
## 135:    0.4788   0.9996   3.4608   0.4429   0.0725   0.0212   0.4738
## 136:    0.4736   0.9941   3.4609   0.4257   0.0721   0.0202   0.4765
## 137:    0.5135   1.0050   3.4650   0.4808   0.0685   0.0192   0.4929
## 138:    0.5037   1.0134   3.4640   0.4617   0.0673   0.0182   0.4583
## 139:    0.4580   1.0140   3.4590   0.4430   0.0695   0.0173   0.4582
## 140:    0.4554   1.0406   3.4555   0.4401   0.0692   0.0165   0.4809
## 141:    0.4652   1.0116   3.4584   0.4410   0.0732   0.0167   0.4540
## 142:    0.4681   0.9963   3.4702   0.4189   0.0738   0.0164   0.4898
## 143:    0.4680   1.0157   3.4646   0.4407   0.0833   0.0195   0.4852
## 144:    0.5092   1.0186   3.4736   0.4186   0.0791   0.0185   0.4794
## 145:    0.4775   1.0224   3.4537   0.4057   0.0751   0.0194   0.4598
## 146:    0.4477   1.0231   3.4559   0.4141   0.0755   0.0184   0.4565
## 147:    0.4491   1.0038   3.4440   0.3934   0.0717   0.0175   0.4539
## 148:    0.4138   1.0081   3.4505   0.3766   0.0681   0.0167   0.4592
## 149:    0.4358   1.0014   3.4566   0.3593   0.0740   0.0181   0.4525
## 150:    0.4642   0.9971   3.4466   0.3686   0.0714   0.0172   0.4834
## 151:    0.3957   1.0290   3.4428   0.3502   0.0678   0.0166   0.4597
## 152:    0.4385   1.0303   3.4418   0.4135   0.0751   0.0182   0.4428
## 153:    0.4311   1.0241   3.4551   0.4449   0.0695   0.0211   0.4585
## 154:    0.4526   1.0361   3.4580   0.4451   0.0804   0.0216   0.4675
## 155:    0.4456   1.0099   3.4491   0.5220   0.0655   0.0260   0.4651
## 156:    0.4692   1.0232   3.4570   0.4744   0.0750   0.0272   0.4873
## 157:    0.4455   1.0076   3.4554   0.4163   0.0657   0.0275   0.4962
## 158:    0.4667   1.0137   3.4557   0.4095   0.0575   0.0256   0.4879
## 159:    0.4116   1.0284   3.4529   0.3624   0.0561   0.0203   0.4950
## 160:    0.4460   0.9918   3.4546   0.4222   0.0633   0.0187   0.4917
## 161:    0.4045   1.0219   3.4411   0.3363   0.0583   0.0210   0.4802
## 162:    0.4111   1.0408   3.4360   0.4027   0.0551   0.0216   0.4717
## 163:    0.4583   1.0217   3.4334   0.4395   0.0513   0.0194   0.4768
## 164:    0.4343   1.0235   3.4361   0.4231   0.0466   0.0197   0.4779
## 165:    0.4498   1.0205   3.4460   0.4112   0.0505   0.0209   0.4710
## 166:    0.4655   1.0353   3.4502   0.4515   0.0434   0.0244   0.4772
## 167:    0.4715   1.0477   3.4591   0.3925   0.0515   0.0259   0.4848
## 168:    0.4719   1.0397   3.4566   0.3975   0.0533   0.0251   0.4815
## 169:    0.4835   1.0503   3.4514   0.3927   0.0596   0.0228   0.4881
## 170:    0.4904   1.0318   3.4596   0.3819   0.0535   0.0245   0.4970
## 171:    0.4790   1.0233   3.4594   0.3958   0.0581   0.0266   0.4693
## 172:    0.4367   1.0286   3.4543   0.3950   0.0483   0.0240   0.4750
## 173:    0.4349   1.0299   3.4430   0.3543   0.0537   0.0328   0.4562
## 174:    0.4384   1.0341   3.4546   0.3507   0.0429   0.0312   0.4850
## 175:    0.4110   1.0363   3.4397   0.3697   0.0562   0.0320   0.4905
## 176:    0.4096   1.0352   3.4566   0.3879   0.0568   0.0247   0.4872
## 177:    0.4624   1.0183   3.4540   0.4842   0.0609   0.0292   0.4606
## 178:    0.4544   1.0014   3.4640   0.4038   0.0670   0.0248   0.4518
## 179:    0.4937   1.0053   3.4593   0.4311   0.0793   0.0215   0.4725
## 180:    0.4610   1.0052   3.4684   0.3130   0.0739   0.0202   0.4899
## 181:    0.4457   1.0111   3.4327   0.3551   0.0622   0.0206   0.4881
## 182:    0.4208   1.0181   3.4365   0.3383   0.0822   0.0203   0.4912
## 183:    0.4391   1.0126   3.4420   0.3760   0.0710   0.0206   0.4885
## 184:    0.4328   1.0152   3.4418   0.4418   0.0662   0.0201   0.4694
## 185:    0.4007   1.0374   3.4336   0.4132   0.0730   0.0258   0.4663
## 186:    0.3875   1.0509   3.4277   0.4124   0.0737   0.0292   0.4863
## 187:    0.4129   1.0251   3.4382   0.3934   0.0605   0.0311   0.4913
## 188:    0.4050   1.0465   3.4394   0.4021   0.0719   0.0252   0.4824
## 189:    0.4270   1.0324   3.4475   0.4149   0.0642   0.0241   0.4776
## 190:    0.4604   1.0185   3.4590   0.3588   0.0572   0.0247   0.4623
## 191:    0.4564   1.0253   3.4565   0.3920   0.0646   0.0253   0.4507
## 192:    0.4462   1.0148   3.4547   0.3613   0.0745   0.0207   0.4635
## 193:    0.4690   1.0323   3.4516   0.3870   0.0699   0.0217   0.4650
## 194:    0.4237   1.0227   3.4307   0.4119   0.0629   0.0157   0.4844
## 195:    0.4132   1.0418   3.4191   0.3738   0.0626   0.0156   0.4908
## 196:    0.4215   1.0304   3.4331   0.4396   0.0816   0.0158   0.4810
## 197:    0.3767   1.0441   3.4434   0.3869   0.0706   0.0170   0.5149
## 198:    0.4390   1.0243   3.4298   0.4769   0.0739   0.0175   0.4693
## 199:    0.4173   1.0072   3.4381   0.4556   0.0734   0.0178   0.4568
## 200:    0.4224   1.0074   3.4394   0.4044   0.0729   0.0193   0.4768
## 201:    0.4245   1.0067   3.4442   0.3952   0.0739   0.0198   0.4715
## 202:    0.4220   1.0110   3.4439   0.4072   0.0720   0.0211   0.4728
## 203:    0.4319   1.0094   3.4422   0.4291   0.0726   0.0217   0.4677
## 204:    0.4344   1.0041   3.4441   0.4368   0.0729   0.0208   0.4693
## 205:    0.4370   1.0086   3.4435   0.4327   0.0743   0.0211   0.4724
## 206:    0.4413   1.0141   3.4445   0.4392   0.0737   0.0208   0.4756
## 207:    0.4372   1.0164   3.4436   0.4333   0.0716   0.0207   0.4763
## 208:    0.4371   1.0162   3.4439   0.4237   0.0692   0.0210   0.4770
## 209:    0.4388   1.0155   3.4436   0.4289   0.0681   0.0211   0.4751
## 210:    0.4398   1.0138   3.4447   0.4288   0.0674   0.0211   0.4734
## 211:    0.4438   1.0140   3.4459   0.4319   0.0679   0.0210   0.4713
## 212:    0.4469   1.0123   3.4466   0.4305   0.0677   0.0208   0.4713
## 213:    0.4485   1.0098   3.4471   0.4290   0.0681   0.0205   0.4730
## 214:    0.4530   1.0094   3.4477   0.4334   0.0690   0.0203   0.4742
## 215:    0.4545   1.0090   3.4489   0.4332   0.0699   0.0202   0.4744
## 216:    0.4583   1.0073   3.4497   0.4417   0.0700   0.0201   0.4762
## 217:    0.4604   1.0077   3.4503   0.4452   0.0699   0.0201   0.4759
## 218:    0.4626   1.0079   3.4503   0.4496   0.0696   0.0201   0.4763
## 219:    0.4624   1.0075   3.4498   0.4515   0.0693   0.0200   0.4768
## 220:    0.4602   1.0079   3.4497   0.4489   0.0691   0.0200   0.4768
## 221:    0.4581   1.0083   3.4493   0.4453   0.0688   0.0201   0.4768
## 222:    0.4584   1.0087   3.4494   0.4475   0.0686   0.0202   0.4772
## 223:    0.4601   1.0084   3.4499   0.4486   0.0683   0.0204   0.4766
## 224:    0.4629   1.0089   3.4505   0.4514   0.0681   0.0206   0.4759
## 225:    0.4630   1.0076   3.4510   0.4510   0.0679   0.0206   0.4761
## 226:    0.4642   1.0062   3.4513   0.4513   0.0680   0.0207   0.4762
## 227:    0.4646   1.0059   3.4516   0.4495   0.0682   0.0207   0.4758
## 228:    0.4647   1.0068   3.4514   0.4491   0.0680   0.0207   0.4761
## 229:    0.4643   1.0066   3.4512   0.4489   0.0678   0.0208   0.4759
## 230:    0.4635   1.0067   3.4508   0.4473   0.0678   0.0209   0.4760
## 231:    0.4631   1.0070   3.4511   0.4443   0.0675   0.0210   0.4762
## 232:    0.4629   1.0071   3.4513   0.4432   0.0674   0.0209   0.4757
## 233:    0.4623   1.0063   3.4515   0.4448   0.0673   0.0209   0.4762
## 234:    0.4615   1.0065   3.4515   0.4432   0.0672   0.0209   0.4765
## 235:    0.4608   1.0064   3.4511   0.4419   0.0670   0.0210   0.4762
## 236:    0.4606   1.0071   3.4509   0.4405   0.0669   0.0210   0.4761
## 237:    0.4607   1.0067   3.4511   0.4405   0.0669   0.0211   0.4767
## 238:    0.4611   1.0073   3.4510   0.4401   0.0671   0.0211   0.4779
## 239:    0.4608   1.0078   3.4510   0.4394   0.0672   0.0210   0.4780
## 240:    0.4609   1.0079   3.4512   0.4390   0.0674   0.0210   0.4776
## 241:    0.4620   1.0072   3.4514   0.4393   0.0676   0.0210   0.4776
## 242:    0.4624   1.0069   3.4514   0.4384   0.0680   0.0210   0.4779
## 243:    0.4624   1.0072   3.4514   0.4370   0.0684   0.0210   0.4780
## 244:    0.4619   1.0073   3.4516   0.4345   0.0687   0.0209   0.4786
## 245:    0.4618   1.0068   3.4519   0.4321   0.0688   0.0208   0.4791
## 246:    0.4620   1.0065   3.4520   0.4303   0.0690   0.0208   0.4797
## 247:    0.4624   1.0065   3.4523   0.4300   0.0692   0.0209   0.4800
## 248:    0.4626   1.0065   3.4526   0.4290   0.0691   0.0209   0.4797
## 249:    0.4622   1.0067   3.4526   0.4280   0.0691   0.0209   0.4795
## 250:    0.4630   1.0072   3.4529   0.4283   0.0690   0.0209   0.4794
## 251:    0.4640   1.0074   3.4533   0.4293   0.0691   0.0209   0.4790
## 252:    0.4646   1.0076   3.4538   0.4306   0.0690   0.0209   0.4791
## 253:    0.4647   1.0078   3.4540   0.4311   0.0688   0.0209   0.4795
## 254:    0.4644   1.0081   3.4542   0.4316   0.0689   0.0208   0.4795
## 255:    0.4641   1.0085   3.4543   0.4304   0.0690   0.0209   0.4797
## 256:    0.4640   1.0086   3.4542   0.4303   0.0689   0.0209   0.4792
## 257:    0.4636   1.0082   3.4541   0.4300   0.0687   0.0208   0.4790
## 258:    0.4634   1.0079   3.4539   0.4316   0.0688   0.0209   0.4786
## 259:    0.4631   1.0077   3.4538   0.4314   0.0689   0.0209   0.4781
## 260:    0.4628   1.0080   3.4539   0.4310   0.0688   0.0209   0.4780
## 261:    0.4631   1.0080   3.4541   0.4300   0.0688   0.0209   0.4779
## 262:    0.4628   1.0082   3.4541   0.4287   0.0690   0.0209   0.4778
## 263:    0.4626   1.0083   3.4542   0.4280   0.0689   0.0209   0.4778
## 264:    0.4621   1.0087   3.4541   0.4281   0.0689   0.0208   0.4781
## 265:    0.4621   1.0089   3.4540   0.4285   0.0692   0.0208   0.4782
## 266:    0.4620   1.0092   3.4539   0.4300   0.0691   0.0207   0.4782
## 267:    0.4617   1.0096   3.4538   0.4320   0.0692   0.0207   0.4783
## 268:    0.4620   1.0098   3.4536   0.4329   0.0691   0.0207   0.4786
## 269:    0.4622   1.0099   3.4535   0.4326   0.0691   0.0206   0.4788
## 270:    0.4622   1.0103   3.4532   0.4333   0.0692   0.0206   0.4785
## 271:    0.4621   1.0107   3.4530   0.4330   0.0691   0.0205   0.4787
## 272:    0.4623   1.0107   3.4528   0.4326   0.0693   0.0205   0.4790
## 273:    0.4619   1.0111   3.4528   0.4316   0.0695   0.0205   0.4791
## 274:    0.4618   1.0114   3.4529   0.4301   0.0697   0.0204   0.4792
## 275:    0.4618   1.0115   3.4529   0.4293   0.0699   0.0204   0.4789
## 276:    0.4615   1.0116   3.4529   0.4290   0.0700   0.0203   0.4788
## 277:    0.4606   1.0117   3.4529   0.4281   0.0699   0.0203   0.4789
## 278:    0.4603   1.0116   3.4529   0.4280   0.0697   0.0203   0.4791
## 279:    0.4602   1.0114   3.4530   0.4281   0.0695   0.0203   0.4793
## 280:    0.4602   1.0114   3.4532   0.4279   0.0695   0.0203   0.4792
## 281:    0.4604   1.0115   3.4534   0.4283   0.0694   0.0203   0.4792
## 282:    0.4609   1.0118   3.4535   0.4296   0.0695   0.0202   0.4792
## 283:    0.4610   1.0120   3.4536   0.4308   0.0694   0.0202   0.4799
## 284:    0.4605   1.0121   3.4534   0.4321   0.0693   0.0202   0.4800
## 285:    0.4600   1.0124   3.4531   0.4318   0.0692   0.0202   0.4798
## 286:    0.4595   1.0128   3.4529   0.4320   0.0692   0.0201   0.4797
## 287:    0.4589   1.0133   3.4525   0.4321   0.0693   0.0201   0.4796
## 288:    0.4587   1.0134   3.4523   0.4316   0.0694   0.0201   0.4798
## 289:    0.4579   1.0134   3.4521   0.4304   0.0695   0.0201   0.4799
## 290:    0.4577   1.0135   3.4519   0.4304   0.0696   0.0201   0.4800
## 291:    0.4577   1.0140   3.4519   0.4310   0.0697   0.0201   0.4799
## 292:    0.4577   1.0141   3.4517   0.4316   0.0699   0.0201   0.4799
## 293:    0.4575   1.0141   3.4516   0.4319   0.0699   0.0201   0.4802
## 294:    0.4575   1.0141   3.4514   0.4323   0.0699   0.0202   0.4804
## 295:    0.4574   1.0138   3.4514   0.4326   0.0699   0.0202   0.4803
## 296:    0.4572   1.0139   3.4515   0.4318   0.0698   0.0202   0.4805
## 297:    0.4571   1.0140   3.4514   0.4320   0.0698   0.0203   0.4806
## 298:    0.4571   1.0140   3.4514   0.4314   0.0698   0.0203   0.4808
## 299:    0.4573   1.0140   3.4514   0.4317   0.0699   0.0202   0.4809
## 300:    0.4575   1.0140   3.4515   0.4322   0.0699   0.0202   0.4808
## 301:    0.4577   1.0138   3.4514   0.4315   0.0699   0.0201   0.4808
## 302:    0.4579   1.0139   3.4515   0.4309   0.0699   0.0201   0.4806
## 303:    0.4582   1.0138   3.4516   0.4304   0.0699   0.0202   0.4804
## 304:    0.4583   1.0140   3.4516   0.4309   0.0698   0.0202   0.4804
## 305:    0.4584   1.0138   3.4515   0.4304   0.0698   0.0202   0.4805
## 306:    0.4579   1.0139   3.4513   0.4301   0.0698   0.0202   0.4805
## 307:    0.4575   1.0138   3.4512   0.4292   0.0698   0.0202   0.4807
## 308:    0.4571   1.0137   3.4510   0.4291   0.0698   0.0202   0.4809
## 309:    0.4566   1.0135   3.4509   0.4291   0.0698   0.0202   0.4812
## 310:    0.4566   1.0135   3.4507   0.4294   0.0699   0.0202   0.4816
## 311:    0.4567   1.0133   3.4507   0.4296   0.0699   0.0201   0.4816
## 312:    0.4564   1.0133   3.4506   0.4300   0.0701   0.0201   0.4817
## 313:    0.4561   1.0131   3.4504   0.4300   0.0701   0.0200   0.4820
## 314:    0.4556   1.0129   3.4504   0.4296   0.0701   0.0200   0.4821
## 315:    0.4555   1.0129   3.4504   0.4296   0.0701   0.0199   0.4821
## 316:    0.4556   1.0130   3.4503   0.4297   0.0702   0.0199   0.4821
## 317:    0.4556   1.0132   3.4503   0.4290   0.0702   0.0199   0.4821
## 318:    0.4556   1.0134   3.4503   0.4286   0.0702   0.0199   0.4821
## 319:    0.4554   1.0135   3.4503   0.4279   0.0702   0.0199   0.4823
## 320:    0.4551   1.0134   3.4502   0.4278   0.0702   0.0198   0.4823
## 321:    0.4546   1.0136   3.4500   0.4277   0.0701   0.0198   0.4823
## 322:    0.4547   1.0136   3.4499   0.4287   0.0701   0.0198   0.4822
## 323:    0.4546   1.0136   3.4498   0.4291   0.0701   0.0198   0.4820
## 324:    0.4544   1.0138   3.4497   0.4298   0.0701   0.0198   0.4819
## 325:    0.4544   1.0140   3.4496   0.4298   0.0701   0.0198   0.4818
## 326:    0.4542   1.0139   3.4495   0.4298   0.0701   0.0198   0.4817
## 327:    0.4545   1.0141   3.4495   0.4309   0.0701   0.0198   0.4815
## 328:    0.4545   1.0141   3.4494   0.4315   0.0701   0.0198   0.4815
## 329:    0.4547   1.0142   3.4495   0.4318   0.0701   0.0198   0.4814
## 330:    0.4544   1.0142   3.4495   0.4317   0.0701   0.0198   0.4813
## 331:    0.4544   1.0143   3.4495   0.4311   0.0701   0.0198   0.4813
## 332:    0.4545   1.0145   3.4496   0.4310   0.0701   0.0198   0.4814
## 333:    0.4546   1.0145   3.4495   0.4313   0.0702   0.0197   0.4815
## 334:    0.4543   1.0145   3.4494   0.4314   0.0702   0.0197   0.4814
## 335:    0.4543   1.0146   3.4492   0.4318   0.0703   0.0197   0.4813
## 336:    0.4536   1.0149   3.4490   0.4318   0.0704   0.0197   0.4814
## 337:    0.4533   1.0153   3.4488   0.4322   0.0706   0.0197   0.4812
## 338:    0.4533   1.0155   3.4488   0.4323   0.0708   0.0197   0.4811
## 339:    0.4532   1.0157   3.4488   0.4318   0.0708   0.0196   0.4811
## 340:    0.4532   1.0155   3.4488   0.4318   0.0709   0.0196   0.4811
## 341:    0.4535   1.0154   3.4489   0.4317   0.0709   0.0196   0.4811
## 342:    0.4534   1.0153   3.4489   0.4312   0.0709   0.0196   0.4811
## 343:    0.4532   1.0153   3.4489   0.4307   0.0710   0.0196   0.4810
## 344:    0.4532   1.0153   3.4489   0.4306   0.0709   0.0196   0.4810
## 345:    0.4533   1.0153   3.4490   0.4303   0.0708   0.0196   0.4810
## 346:    0.4531   1.0154   3.4489   0.4300   0.0707   0.0196   0.4809
## 347:    0.4529   1.0155   3.4488   0.4300   0.0707   0.0196   0.4809
## 348:    0.4526   1.0156   3.4486   0.4300   0.0706   0.0196   0.4810
## 349:    0.4523   1.0157   3.4485   0.4301   0.0706   0.0196   0.4810
## 350:    0.4520   1.0157   3.4484   0.4301   0.0705   0.0196   0.4809
## 351:    0.4519   1.0157   3.4483   0.4303   0.0704   0.0196   0.4809
## 352:    0.4517   1.0158   3.4482   0.4303   0.0703   0.0196   0.4811
## 353:    0.4519   1.0160   3.4482   0.4305   0.0703   0.0196   0.4811
## 354:    0.4519   1.0160   3.4481   0.4304   0.0703   0.0196   0.4811
## 355:    0.4521   1.0160   3.4481   0.4305   0.0704   0.0196   0.4810
## 356:    0.4520   1.0158   3.4481   0.4298   0.0704   0.0196   0.4811
## 357:    0.4519   1.0159   3.4481   0.4296   0.0704   0.0196   0.4811
## 358:    0.4519   1.0160   3.4482   0.4291   0.0704   0.0195   0.4809
## 359:    0.4517   1.0161   3.4482   0.4288   0.0704   0.0195   0.4808
## 360:    0.4515   1.0160   3.4481   0.4289   0.0704   0.0195   0.4807
## 361:    0.4512   1.0161   3.4481   0.4283   0.0703   0.0195   0.4806
## 362:    0.4511   1.0161   3.4481   0.4281   0.0703   0.0195   0.4804
## 363:    0.4511   1.0160   3.4481   0.4280   0.0702   0.0195   0.4802
## 364:    0.4512   1.0160   3.4481   0.4282   0.0701   0.0195   0.4802
## 365:    0.4512   1.0158   3.4482   0.4281   0.0701   0.0196   0.4802
## 366:    0.4510   1.0158   3.4482   0.4274   0.0700   0.0196   0.4804
## 367:    0.4510   1.0158   3.4482   0.4270   0.0700   0.0196   0.4804
## 368:    0.4511   1.0158   3.4482   0.4270   0.0700   0.0196   0.4803
## 369:    0.4513   1.0158   3.4482   0.4273   0.0700   0.0196   0.4802
## 370:    0.4514   1.0157   3.4483   0.4271   0.0699   0.0196   0.4803
## 371:    0.4513   1.0158   3.4482   0.4269   0.0700   0.0197   0.4802
## 372:    0.4509   1.0161   3.4481   0.4266   0.0700   0.0197   0.4802
## 373:    0.4505   1.0163   3.4479   0.4263   0.0700   0.0197   0.4801
## 374:    0.4502   1.0164   3.4478   0.4260   0.0700   0.0196   0.4800
## 375:    0.4499   1.0164   3.4477   0.4258   0.0700   0.0196   0.4799
## 376:    0.4496   1.0166   3.4477   0.4254   0.0700   0.0196   0.4798
## 377:    0.4494   1.0167   3.4477   0.4251   0.0700   0.0196   0.4796
## 378:    0.4492   1.0167   3.4476   0.4250   0.0700   0.0196   0.4796
## 379:    0.4490   1.0166   3.4475   0.4251   0.0700   0.0196   0.4796
## 380:    0.4488   1.0166   3.4474   0.4250   0.0701   0.0196   0.4796
## 381:    0.4486   1.0166   3.4474   0.4249   0.0701   0.0196   0.4796
## 382:    0.4484   1.0167   3.4474   0.4245   0.0701   0.0195   0.4795
## 383:    0.4484   1.0166   3.4474   0.4244   0.0700   0.0195   0.4794
## 384:    0.4483   1.0165   3.4474   0.4240   0.0700   0.0196   0.4794
## 385:    0.4484   1.0164   3.4474   0.4242   0.0699   0.0196   0.4793
## 386:    0.4486   1.0165   3.4475   0.4243   0.0700   0.0196   0.4792
## 387:    0.4488   1.0166   3.4476   0.4239   0.0699   0.0196   0.4792
## 388:    0.4489   1.0166   3.4477   0.4240   0.0699   0.0196   0.4791
## 389:    0.4488   1.0165   3.4477   0.4239   0.0699   0.0196   0.4791
## 390:    0.4487   1.0166   3.4476   0.4238   0.0700   0.0196   0.4789
## 391:    0.4489   1.0166   3.4476   0.4238   0.0700   0.0196   0.4789
## 392:    0.4489   1.0166   3.4476   0.4239   0.0699   0.0196   0.4790
## 393:    0.4489   1.0166   3.4476   0.4241   0.0699   0.0195   0.4790
## 394:    0.4491   1.0167   3.4475   0.4241   0.0699   0.0195   0.4790
## 395:    0.4492   1.0167   3.4475   0.4236   0.0699   0.0195   0.4791
## 396:    0.4492   1.0168   3.4476   0.4237   0.0698   0.0195   0.4791
## 397:    0.4494   1.0165   3.4477   0.4237   0.0698   0.0195   0.4790
## 398:    0.4498   1.0164   3.4479   0.4237   0.0698   0.0195   0.4790
## 399:    0.4502   1.0162   3.4481   0.4235   0.0699   0.0196   0.4789
## 400:    0.4504   1.0161   3.4482   0.4234   0.0699   0.0196   0.4789
## 401:    0.4505   1.0161   3.4482   0.4231   0.0699   0.0196   0.4791
## 402:    0.4505   1.0161   3.4483   0.4227   0.0699   0.0196   0.4792
## 403:    0.4508   1.0160   3.4483   0.4227   0.0699   0.0196   0.4792
## 404:    0.4509   1.0160   3.4483   0.4227   0.0699   0.0196   0.4791
## 405:    0.4509   1.0160   3.4483   0.4228   0.0699   0.0196   0.4791
## 406:    0.4509   1.0160   3.4483   0.4228   0.0699   0.0196   0.4791
## 407:    0.4509   1.0159   3.4484   0.4229   0.0699   0.0196   0.4790
## 408:    0.4512   1.0160   3.4484   0.4230   0.0700   0.0196   0.4790
## 409:    0.4511   1.0160   3.4484   0.4228   0.0700   0.0196   0.4790
## 410:    0.4509   1.0160   3.4483   0.4226   0.0700   0.0196   0.4790
## 411:    0.4508   1.0160   3.4482   0.4226   0.0700   0.0196   0.4791
## 412:    0.4508   1.0161   3.4482   0.4220   0.0700   0.0196   0.4792
## 413:    0.4505   1.0162   3.4482   0.4214   0.0699   0.0196   0.4793
## 414:    0.4503   1.0163   3.4482   0.4217   0.0699   0.0196   0.4792
## 415:    0.4504   1.0163   3.4481   0.4217   0.0699   0.0196   0.4791
## 416:    0.4503   1.0164   3.4481   0.4216   0.0698   0.0196   0.4792
## 417:    0.4503   1.0164   3.4481   0.4216   0.0698   0.0196   0.4791
## 418:    0.4503   1.0164   3.4481   0.4215   0.0699   0.0196   0.4790
## 419:    0.4504   1.0164   3.4481   0.4217   0.0699   0.0197   0.4789
## 420:    0.4506   1.0165   3.4482   0.4216   0.0700   0.0196   0.4788
## 421:    0.4505   1.0165   3.4483   0.4214   0.0700   0.0196   0.4788
## 422:    0.4507   1.0163   3.4483   0.4214   0.0700   0.0196   0.4787
## 423:    0.4509   1.0163   3.4484   0.4213   0.0701   0.0196   0.4787
## 424:    0.4507   1.0162   3.4483   0.4214   0.0701   0.0196   0.4786
## 425:    0.4507   1.0163   3.4482   0.4216   0.0701   0.0196   0.4785
## 426:    0.4507   1.0164   3.4482   0.4217   0.0701   0.0196   0.4784
## 427:    0.4506   1.0165   3.4482   0.4218   0.0701   0.0196   0.4784
## 428:    0.4507   1.0165   3.4482   0.4215   0.0701   0.0196   0.4784
## 429:    0.4508   1.0165   3.4483   0.4213   0.0700   0.0196   0.4785
## 430:    0.4507   1.0165   3.4483   0.4210   0.0701   0.0196   0.4786
## 431:    0.4505   1.0165   3.4483   0.4208   0.0701   0.0196   0.4785
## 432:    0.4504   1.0166   3.4483   0.4207   0.0701   0.0196   0.4784
## 433:    0.4503   1.0167   3.4483   0.4207   0.0702   0.0196   0.4784
## 434:    0.4503   1.0166   3.4483   0.4206   0.0702   0.0196   0.4784
## 435:    0.4502   1.0166   3.4483   0.4203   0.0702   0.0196   0.4783
## 436:    0.4502   1.0166   3.4484   0.4201   0.0702   0.0196   0.4784
## 437:    0.4503   1.0166   3.4484   0.4202   0.0703   0.0196   0.4784
## 438:    0.4501   1.0167   3.4483   0.4200   0.0703   0.0195   0.4784
## 439:    0.4501   1.0168   3.4483   0.4200   0.0703   0.0195   0.4784
## 440:    0.4502   1.0168   3.4484   0.4198   0.0703   0.0195   0.4784
## 441:    0.4504   1.0168   3.4484   0.4199   0.0703   0.0195   0.4783
## 442:    0.4504   1.0169   3.4485   0.4200   0.0702   0.0195   0.4783
## 443:    0.4506   1.0169   3.4485   0.4202   0.0702   0.0195   0.4782
## 444:    0.4505   1.0170   3.4484   0.4201   0.0703   0.0195   0.4783
## 445:    0.4505   1.0170   3.4483   0.4205   0.0703   0.0194   0.4783
## 446:    0.4504   1.0171   3.4483   0.4207   0.0704   0.0194   0.4784
## 447:    0.4506   1.0171   3.4483   0.4209   0.0704   0.0194   0.4784
## 448:    0.4507   1.0171   3.4484   0.4207   0.0704   0.0194   0.4783
## 449:    0.4509   1.0171   3.4485   0.4203   0.0704   0.0194   0.4783
## 450:    0.4510   1.0171   3.4486   0.4201   0.0704   0.0194   0.4783
## 451:    0.4512   1.0170   3.4487   0.4201   0.0703   0.0194   0.4783
## 452:    0.4515   1.0170   3.4488   0.4200   0.0703   0.0194   0.4783
## 453:    0.4515   1.0169   3.4488   0.4197   0.0703   0.0194   0.4782
## 454:    0.4516   1.0170   3.4488   0.4194   0.0703   0.0194   0.4781
## 455:    0.4517   1.0170   3.4489   0.4194   0.0702   0.0194   0.4780
## 456:    0.4518   1.0169   3.4488   0.4195   0.0702   0.0194   0.4780
## 457:    0.4518   1.0169   3.4489   0.4195   0.0702   0.0194   0.4780
## 458:    0.4518   1.0169   3.4489   0.4195   0.0701   0.0194   0.4779
## 459:    0.4515   1.0170   3.4488   0.4194   0.0701   0.0194   0.4779
## 460:    0.4513   1.0171   3.4488   0.4192   0.0700   0.0194   0.4779
## 461:    0.4511   1.0172   3.4488   0.4190   0.0700   0.0194   0.4780
## 462:    0.4510   1.0173   3.4488   0.4187   0.0700   0.0194   0.4780
## 463:    0.4510   1.0173   3.4488   0.4184   0.0700   0.0194   0.4781
## 464:    0.4510   1.0174   3.4487   0.4182   0.0700   0.0194   0.4780
## 465:    0.4510   1.0173   3.4487   0.4181   0.0700   0.0194   0.4780
## 466:    0.4509   1.0173   3.4487   0.4177   0.0700   0.0194   0.4781
## 467:    0.4507   1.0172   3.4488   0.4173   0.0700   0.0194   0.4781
## 468:    0.4508   1.0172   3.4488   0.4172   0.0701   0.0194   0.4782
## 469:    0.4508   1.0174   3.4488   0.4174   0.0701   0.0194   0.4783
## 470:    0.4507   1.0174   3.4488   0.4175   0.0702   0.0193   0.4783
## 471:    0.4507   1.0174   3.4487   0.4174   0.0702   0.0193   0.4784
## 472:    0.4507   1.0174   3.4488   0.4173   0.0702   0.0193   0.4784
## 473:    0.4506   1.0174   3.4488   0.4171   0.0702   0.0193   0.4784
## 474:    0.4507   1.0174   3.4488   0.4170   0.0702   0.0193   0.4785
## 475:    0.4507   1.0175   3.4488   0.4169   0.0702   0.0193   0.4785
## 476:    0.4507   1.0175   3.4488   0.4171   0.0702   0.0193   0.4785
## 477:    0.4506   1.0175   3.4488   0.4170   0.0702   0.0193   0.4784
## 478:    0.4505   1.0175   3.4488   0.4169   0.0702   0.0193   0.4784
## 479:    0.4507   1.0174   3.4489   0.4170   0.0703   0.0193   0.4786
## 480:    0.4506   1.0174   3.4489   0.4167   0.0704   0.0193   0.4787
## 481:    0.4506   1.0175   3.4489   0.4164   0.0704   0.0193   0.4788
## 482:    0.4506   1.0175   3.4489   0.4164   0.0703   0.0193   0.4788
## 483:    0.4506   1.0174   3.4489   0.4165   0.0703   0.0193   0.4788
## 484:    0.4506   1.0173   3.4489   0.4166   0.0703   0.0193   0.4788
## 485:    0.4507   1.0174   3.4489   0.4168   0.0703   0.0193   0.4788
## 486:    0.4507   1.0174   3.4489   0.4166   0.0703   0.0193   0.4788
## 487:    0.4509   1.0174   3.4490   0.4166   0.0703   0.0193   0.4787
## 488:    0.4509   1.0173   3.4490   0.4165   0.0703   0.0193   0.4787
## 489:    0.4511   1.0173   3.4490   0.4166   0.0703   0.0193   0.4787
## 490:    0.4513   1.0173   3.4491   0.4167   0.0703   0.0193   0.4787
## 491:    0.4513   1.0173   3.4491   0.4166   0.0703   0.0193   0.4787
## 492:    0.4514   1.0173   3.4492   0.4164   0.0703   0.0193   0.4787
## 493:    0.4513   1.0173   3.4492   0.4163   0.0703   0.0193   0.4787
## 494:    0.4513   1.0173   3.4491   0.4161   0.0703   0.0193   0.4787
## 495:    0.4513   1.0173   3.4491   0.4160   0.0703   0.0193   0.4786
## 496:    0.4514   1.0173   3.4491   0.4160   0.0703   0.0193   0.4786
## 497:    0.4513   1.0173   3.4491   0.4163   0.0702   0.0193   0.4786
## 498:    0.4513   1.0173   3.4490   0.4163   0.0702   0.0193   0.4785
## 499:    0.4513   1.0174   3.4490   0.4165   0.0702   0.0193   0.4784
## 500:    0.4513   1.0173   3.4489   0.4164   0.0702   0.0193   0.4783</code></pre>
<pre><code>## Calculating covariance matrix</code></pre>
<pre><code>## [====|====|====|====|====|====|====|====|====|====</code></pre>
<pre><code>## Calculating residuals/tables
## done.
## Calculating -2LL by Gaussian quadrature (nnodes=3,nsd=1.6)</code></pre>
<pre><code>## [====|====|====|====|====|====|====|====|====|====</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit2 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/nlmixr.html">nlmixr</a></span>(one.compartment, <span class="dt">data=</span>theo_sd, <span class="dt">est=</span><span class="st">"saem"</span>)</code></pre></div>
<pre><code>## Loading model already run (/home/matt/R/x86_64-pc-linux-gnu-library/3.5/nlmixr/nlmixr-one.compartment-theo_sd-saem-fc93affe842124d57c37f8d5220fd1b9.rds)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit3 &lt;-<span class="st"> </span>one.compartment <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/saem.fit.html">saem.fit</a></span>(<span class="dt">data=</span>theo_sd)</code></pre></div>
<pre><code>## Compiling RxODE equations...done.</code></pre>
<pre><code>## 1:    0.2288   0.9677   3.4737   0.5700   0.2850   0.0950   4.5245
## 2:    0.3623   0.9821   3.5318   0.5415   0.2707   0.0902   1.8046
## 3:    0.4864   0.9181   3.4872   0.5144   0.2572   0.0857   0.9422
## 4:    0.4480   0.9416   3.4843   0.4887   0.2444   0.0815   0.6940
## 5:    0.4844   0.9591   3.4754   0.4643   0.2321   0.0774   0.6019
## 6:    0.4986   0.9687   3.4752   0.4411   0.2205   0.0735   0.5056
## 7:    0.4577   0.9953   3.4634   0.4251   0.2095   0.0698   0.5076
## 8:    0.4473   0.9911   3.4666   0.4039   0.1990   0.0663   0.5155
## 9:    0.4188   0.9755   3.4615   0.3837   0.1891   0.0630   0.5210
## 10:    0.4349   0.9798   3.4521   0.4305   0.1796   0.0599   0.4901
## 11:    0.4537   0.9976   3.4548   0.4089   0.1706   0.0569   0.4911
## 12:    0.4421   1.0104   3.4458   0.3885   0.1621   0.0540   0.4628
## 13:    0.3941   1.0454   3.4243   0.3691   0.1540   0.0513   0.4783
## 14:    0.4189   1.0204   3.4380   0.4545   0.1463   0.0488   0.5002
## 15:    0.4506   1.0202   3.4468   0.4318   0.1390   0.0463   0.4889
## 16:    0.4552   1.0112   3.4524   0.4209   0.1320   0.0440   0.5038
## 17:    0.4542   1.0115   3.4558   0.4164   0.1254   0.0418   0.4658
## 18:    0.4820   0.9828   3.4521   0.4451   0.1192   0.0397   0.5021
## 19:    0.4339   0.9924   3.4505   0.4228   0.1132   0.0377   0.4914
## 20:    0.4527   1.0041   3.4472   0.4037   0.1075   0.0358   0.4928
## 21:    0.4404   1.0079   3.4558   0.3885   0.1022   0.0341   0.4739
## 22:    0.4625   1.0138   3.4599   0.4469   0.0971   0.0324   0.4520
## 23:    0.5104   1.0181   3.4648   0.4535   0.0922   0.0307   0.4667
## 24:    0.5050   1.0228   3.4659   0.4308   0.0876   0.0292   0.4543
## 25:    0.4633   0.9967   3.4608   0.4093   0.0861   0.0277   0.4789
## 26:    0.4183   1.0293   3.4345   0.4183   0.0818   0.0264   0.4644
## 27:    0.4126   1.0361   3.4357   0.3973   0.0777   0.0250   0.4941
## 28:    0.4592   1.0181   3.4429   0.3775   0.0738   0.0238   0.4538
## 29:    0.4413   1.0248   3.4369   0.3586   0.0701   0.0226   0.4801
## 30:    0.4506   1.0195   3.4440   0.3689   0.0672   0.0215   0.4824
## 31:    0.4049   1.0069   3.4520   0.3505   0.0768   0.0204   0.4778
## 32:    0.4292   0.9864   3.4607   0.3939   0.0729   0.0205   0.4702
## 33:    0.4417   1.0151   3.4477   0.4332   0.0693   0.0195   0.4917
## 34:    0.4597   1.0252   3.4485   0.4238   0.0658   0.0185   0.4909
## 35:    0.4485   0.9940   3.4511   0.4026   0.0637   0.0176   0.4766
## 36:    0.4405   1.0103   3.4488   0.3825   0.0658   0.0167   0.4873
## 37:    0.4408   1.0163   3.4572   0.3731   0.0707   0.0195   0.4872
## 38:    0.5014   1.0088   3.4476   0.4544   0.0752   0.0185   0.4844
## 39:    0.5031   0.9852   3.4647   0.4819   0.0715   0.0245   0.4632
## 40:    0.4910   0.9905   3.4762   0.4578   0.0679   0.0272   0.4737
## 41:    0.4276   0.9901   3.4569   0.4349   0.0645   0.0259   0.4968
## 42:    0.4696   1.0088   3.4529   0.4236   0.0656   0.0246   0.4457
## 43:    0.4296   1.0293   3.4341   0.4025   0.0641   0.0233   0.4549
## 44:    0.4268   1.0334   3.4423   0.3823   0.0609   0.0237   0.4758
## 45:    0.4435   1.0397   3.4447   0.4115   0.0585   0.0265   0.4409
## 46:    0.4406   1.0217   3.4500   0.3910   0.0765   0.0252   0.4533
## 47:    0.4454   1.0224   3.4450   0.3841   0.0727   0.0239   0.4644
## 48:    0.4597   1.0215   3.4499   0.4516   0.0691   0.0238   0.4763
## 49:    0.4512   1.0173   3.4484   0.4290   0.0668   0.0239   0.4950
## 50:    0.4538   0.9948   3.4407   0.4076   0.0767   0.0227   0.5089
## 51:    0.4708   1.0340   3.4357   0.4159   0.0729   0.0216   0.4933
## 52:    0.5150   1.0202   3.4583   0.4959   0.0692   0.0205   0.4824
## 53:    0.5019   1.0156   3.4502   0.4711   0.0658   0.0195   0.5123
## 54:    0.4544   1.0083   3.4541   0.4476   0.0654   0.0188   0.5106
## 55:    0.4427   1.0017   3.4534   0.4252   0.0705   0.0191   0.4871
## 56:    0.4411   0.9917   3.4486   0.4039   0.0670   0.0214   0.4881
## 57:    0.4808   1.0063   3.4621   0.3957   0.0668   0.0203   0.4932
## 58:    0.5100   1.0050   3.4567   0.4291   0.0677   0.0193   0.4939
## 59:    0.5064   0.9712   3.4642   0.4676   0.0888   0.0183   0.5044
## 60:    0.4913   0.9699   3.4635   0.4897   0.0844   0.0184   0.5282
## 61:    0.5047   0.9892   3.4614   0.5644   0.0801   0.0187   0.5103
## 62:    0.4536   1.0146   3.4580   0.5362   0.0826   0.0193   0.5128
## 63:    0.4776   1.0017   3.4530   0.5094   0.0915   0.0184   0.4863
## 64:    0.4550   1.0007   3.4565   0.4839   0.0903   0.0176   0.4998
## 65:    0.4857   1.0002   3.4422   0.4597   0.0874   0.0193   0.4952
## 66:    0.4478   1.0116   3.4506   0.4368   0.0878   0.0189   0.4872
## 67:    0.4560   0.9978   3.4400   0.4149   0.0834   0.0198   0.4768
## 68:    0.4015   1.0105   3.4500   0.3942   0.0792   0.0188   0.5248
## 69:    0.4199   1.0082   3.4475   0.4043   0.0752   0.0200   0.5082
## 70:    0.4253   1.0065   3.4493   0.4755   0.0731   0.0205   0.5055
## 71:    0.4117   1.0205   3.4353   0.4518   0.0709   0.0194   0.5004
## 72:    0.4360   0.9896   3.4507   0.4292   0.0794   0.0185   0.4803
## 73:    0.4627   1.0107   3.4625   0.4077   0.0755   0.0175   0.5032
## 74:    0.4423   0.9902   3.4615   0.3951   0.0717   0.0167   0.5050
## 75:    0.4804   0.9934   3.4805   0.3992   0.0838   0.0198   0.4787
## 76:    0.5158   1.0021   3.4882   0.4126   0.0796   0.0189   0.5092
## 77:    0.5218   0.9735   3.4803   0.4015   0.0756   0.0212   0.4962
## 78:    0.4955   0.9901   3.4782   0.4149   0.0723   0.0212   0.4968
## 79:    0.4812   1.0022   3.4688   0.4388   0.0687   0.0226   0.5138
## 80:    0.4961   0.9871   3.4663   0.5095   0.0663   0.0231   0.5008
## 81:    0.5070   1.0060   3.4671   0.4841   0.0629   0.0220   0.4849
## 82:    0.4839   0.9860   3.4730   0.4599   0.0598   0.0277   0.4823
## 83:    0.4757   1.0172   3.4654   0.4473   0.0568   0.0263   0.4652
## 84:    0.4435   0.9975   3.4540   0.4364   0.0540   0.0261   0.4610
## 85:    0.4664   1.0161   3.4677   0.4214   0.0540   0.0248   0.4924
## 86:    0.4662   1.0089   3.4598   0.4003   0.0599   0.0275   0.4604
## 87:    0.4415   1.0119   3.4497   0.3899   0.0569   0.0262   0.4832
## 88:    0.3796   1.0086   3.4436   0.4004   0.0589   0.0249   0.4865
## 89:    0.4269   1.0175   3.4436   0.3804   0.0593   0.0236   0.5350
## 90:    0.4326   1.0242   3.4437   0.4088   0.0563   0.0224   0.5157
## 91:    0.4446   1.0109   3.4282   0.4562   0.0597   0.0216   0.4853
## 92:    0.4320   1.0268   3.4386   0.5057   0.0691   0.0236   0.4781
## 93:    0.3564   1.0149   3.4338   0.4804   0.0698   0.0224   0.5011
## 94:    0.3878   1.0151   3.4224   0.4563   0.0727   0.0213   0.5119
## 95:    0.4563   1.0220   3.4455   0.5434   0.0709   0.0202   0.5027
## 96:    0.4575   1.0088   3.4446   0.5162   0.0673   0.0206   0.4731
## 97:    0.4498   1.0277   3.4474   0.4904   0.0640   0.0197   0.4830
## 98:    0.4713   1.0243   3.4547   0.4659   0.0617   0.0187   0.4752
## 99:    0.4413   1.0028   3.4478   0.4426   0.0587   0.0194   0.4663
## 100:    0.4279   1.0081   3.4471   0.4205   0.0648   0.0213   0.4570
## 101:    0.4195   1.0062   3.4350   0.4386   0.0788   0.0202   0.4638
## 102:    0.4093   1.0121   3.4290   0.4565   0.0749   0.0192   0.4679
## 103:    0.4730   1.0048   3.4494   0.4635   0.0711   0.0201   0.4593
## 104:    0.4535   1.0068   3.4564   0.4917   0.0693   0.0193   0.4936
## 105:    0.4404   1.0082   3.4391   0.5036   0.0828   0.0183   0.5014
## 106:    0.4470   1.0029   3.4488   0.4785   0.0839   0.0174   0.4972
## 107:    0.4493   1.0090   3.4480   0.4990   0.0820   0.0166   0.4727
## 108:    0.4533   1.0076   3.4550   0.4741   0.0779   0.0178   0.4784
## 109:    0.4513   1.0176   3.4609   0.4504   0.0740   0.0176   0.4651
## 110:    0.4804   0.9923   3.4544   0.4616   0.0703   0.0187   0.4615
## 111:    0.4768   0.9979   3.4601   0.4385   0.0801   0.0178   0.4392
## 112:    0.4809   0.9864   3.4540   0.4495   0.0761   0.0187   0.4452
## 113:    0.4422   1.0386   3.4474   0.4592   0.0723   0.0182   0.4465
## 114:    0.4311   1.0411   3.4368   0.4363   0.0771   0.0190   0.4466
## 115:    0.4261   1.0006   3.4460   0.4145   0.0733   0.0197   0.4811
## 116:    0.4618   1.0050   3.4459   0.4178   0.0696   0.0190   0.4804
## 117:    0.4243   1.0276   3.4502   0.3969   0.0758   0.0181   0.4830
## 118:    0.4661   1.0209   3.4537   0.3771   0.0798   0.0177   0.4902
## 119:    0.4684   1.0132   3.4548   0.4747   0.0838   0.0220   0.5065
## 120:    0.4260   1.0016   3.4485   0.4611   0.0796   0.0209   0.4749
## 121:    0.4415   1.0288   3.4409   0.4380   0.0756   0.0199   0.4814
## 122:    0.4389   1.0077   3.4469   0.4161   0.0719   0.0189   0.4544
## 123:    0.4391   1.0456   3.4443   0.4249   0.0683   0.0203   0.4614
## 124:    0.4663   1.0506   3.4504   0.4291   0.0669   0.0197   0.4463
## 125:    0.4714   1.0387   3.4485   0.4077   0.0829   0.0188   0.4568
## 126:    0.4426   1.0411   3.4412   0.4396   0.0891   0.0189   0.4532
## 127:    0.4472   1.0047   3.4338   0.4235   0.0859   0.0206   0.4881
## 128:    0.4413   1.0274   3.4457   0.4504   0.0817   0.0258   0.5163
## 129:    0.4669   1.0151   3.4652   0.4828   0.0776   0.0245   0.4812
## 130:    0.5358   1.0291   3.4502   0.5114   0.0737   0.0233   0.4844
## 131:    0.4486   1.0021   3.4407   0.4858   0.0757   0.0223   0.4845
## 132:    0.4105   1.0228   3.4263   0.4615   0.0845   0.0212   0.5082
## 133:    0.4199   1.0085   3.4401   0.4384   0.0803   0.0201   0.5018
## 134:    0.4689   1.0094   3.4565   0.4267   0.0763   0.0216   0.4707
## 135:    0.4788   0.9996   3.4608   0.4429   0.0725   0.0212   0.4738
## 136:    0.4736   0.9941   3.4609   0.4257   0.0721   0.0202   0.4765
## 137:    0.5135   1.0050   3.4650   0.4808   0.0685   0.0192   0.4929
## 138:    0.5037   1.0134   3.4640   0.4617   0.0673   0.0182   0.4583
## 139:    0.4580   1.0140   3.4590   0.4430   0.0695   0.0173   0.4582
## 140:    0.4554   1.0406   3.4555   0.4401   0.0692   0.0165   0.4809
## 141:    0.4652   1.0116   3.4584   0.4410   0.0732   0.0167   0.4540
## 142:    0.4681   0.9963   3.4702   0.4189   0.0738   0.0164   0.4898
## 143:    0.4680   1.0157   3.4646   0.4407   0.0833   0.0195   0.4852
## 144:    0.5092   1.0186   3.4736   0.4186   0.0791   0.0185   0.4794
## 145:    0.4775   1.0224   3.4537   0.4057   0.0751   0.0194   0.4598
## 146:    0.4477   1.0231   3.4559   0.4141   0.0755   0.0184   0.4565
## 147:    0.4491   1.0038   3.4440   0.3934   0.0717   0.0175   0.4539
## 148:    0.4138   1.0081   3.4505   0.3766   0.0681   0.0167   0.4592
## 149:    0.4358   1.0014   3.4566   0.3593   0.0740   0.0181   0.4525
## 150:    0.4642   0.9971   3.4466   0.3686   0.0714   0.0172   0.4834
## 151:    0.3957   1.0290   3.4428   0.3502   0.0678   0.0166   0.4597
## 152:    0.4385   1.0303   3.4418   0.4135   0.0751   0.0182   0.4428
## 153:    0.4311   1.0241   3.4551   0.4449   0.0695   0.0211   0.4585
## 154:    0.4526   1.0361   3.4580   0.4451   0.0804   0.0216   0.4675
## 155:    0.4456   1.0099   3.4491   0.5220   0.0655   0.0260   0.4651
## 156:    0.4692   1.0232   3.4570   0.4744   0.0750   0.0272   0.4873
## 157:    0.4455   1.0076   3.4554   0.4163   0.0657   0.0275   0.4962
## 158:    0.4667   1.0137   3.4557   0.4095   0.0575   0.0256   0.4879
## 159:    0.4116   1.0284   3.4529   0.3624   0.0561   0.0203   0.4950
## 160:    0.4460   0.9918   3.4546   0.4222   0.0633   0.0187   0.4917
## 161:    0.4045   1.0219   3.4411   0.3363   0.0583   0.0210   0.4802
## 162:    0.4111   1.0408   3.4360   0.4027   0.0551   0.0216   0.4717
## 163:    0.4583   1.0217   3.4334   0.4395   0.0513   0.0194   0.4768
## 164:    0.4343   1.0235   3.4361   0.4231   0.0466   0.0197   0.4779
## 165:    0.4498   1.0205   3.4460   0.4112   0.0505   0.0209   0.4710
## 166:    0.4655   1.0353   3.4502   0.4515   0.0434   0.0244   0.4772
## 167:    0.4715   1.0477   3.4591   0.3925   0.0515   0.0259   0.4848
## 168:    0.4719   1.0397   3.4566   0.3975   0.0533   0.0251   0.4815
## 169:    0.4835   1.0503   3.4514   0.3927   0.0596   0.0228   0.4881
## 170:    0.4904   1.0318   3.4596   0.3819   0.0535   0.0245   0.4970
## 171:    0.4790   1.0233   3.4594   0.3958   0.0581   0.0266   0.4693
## 172:    0.4367   1.0286   3.4543   0.3950   0.0483   0.0240   0.4750
## 173:    0.4349   1.0299   3.4430   0.3543   0.0537   0.0328   0.4562
## 174:    0.4384   1.0341   3.4546   0.3507   0.0429   0.0312   0.4850
## 175:    0.4110   1.0363   3.4397   0.3697   0.0562   0.0320   0.4905
## 176:    0.4096   1.0352   3.4566   0.3879   0.0568   0.0247   0.4872
## 177:    0.4624   1.0183   3.4540   0.4842   0.0609   0.0292   0.4606
## 178:    0.4544   1.0014   3.4640   0.4038   0.0670   0.0248   0.4518
## 179:    0.4937   1.0053   3.4593   0.4311   0.0793   0.0215   0.4725
## 180:    0.4610   1.0052   3.4684   0.3130   0.0739   0.0202   0.4899
## 181:    0.4457   1.0111   3.4327   0.3551   0.0622   0.0206   0.4881
## 182:    0.4208   1.0181   3.4365   0.3383   0.0822   0.0203   0.4912
## 183:    0.4391   1.0126   3.4420   0.3760   0.0710   0.0206   0.4885
## 184:    0.4328   1.0152   3.4418   0.4418   0.0662   0.0201   0.4694
## 185:    0.4007   1.0374   3.4336   0.4132   0.0730   0.0258   0.4663
## 186:    0.3875   1.0509   3.4277   0.4124   0.0737   0.0292   0.4863
## 187:    0.4129   1.0251   3.4382   0.3934   0.0605   0.0311   0.4913
## 188:    0.4050   1.0465   3.4394   0.4021   0.0719   0.0252   0.4824
## 189:    0.4270   1.0324   3.4475   0.4149   0.0642   0.0241   0.4776
## 190:    0.4604   1.0185   3.4590   0.3588   0.0572   0.0247   0.4623
## 191:    0.4564   1.0253   3.4565   0.3920   0.0646   0.0253   0.4507
## 192:    0.4462   1.0148   3.4547   0.3613   0.0745   0.0207   0.4635
## 193:    0.4690   1.0323   3.4516   0.3870   0.0699   0.0217   0.4650
## 194:    0.4237   1.0227   3.4307   0.4119   0.0629   0.0157   0.4844
## 195:    0.4132   1.0418   3.4191   0.3738   0.0626   0.0156   0.4908
## 196:    0.4215   1.0304   3.4331   0.4396   0.0816   0.0158   0.4810
## 197:    0.3767   1.0441   3.4434   0.3869   0.0706   0.0170   0.5149
## 198:    0.4390   1.0243   3.4298   0.4769   0.0739   0.0175   0.4693
## 199:    0.4173   1.0072   3.4381   0.4556   0.0734   0.0178   0.4568
## 200:    0.4224   1.0074   3.4394   0.4044   0.0729   0.0193   0.4768
## 201:    0.4245   1.0067   3.4442   0.3952   0.0739   0.0198   0.4715
## 202:    0.4220   1.0110   3.4439   0.4072   0.0720   0.0211   0.4728
## 203:    0.4319   1.0094   3.4422   0.4291   0.0726   0.0217   0.4677
## 204:    0.4344   1.0041   3.4441   0.4368   0.0729   0.0208   0.4693
## 205:    0.4370   1.0086   3.4435   0.4327   0.0743   0.0211   0.4724
## 206:    0.4413   1.0141   3.4445   0.4392   0.0737   0.0208   0.4756
## 207:    0.4372   1.0164   3.4436   0.4333   0.0716   0.0207   0.4763
## 208:    0.4371   1.0162   3.4439   0.4237   0.0692   0.0210   0.4770
## 209:    0.4388   1.0155   3.4436   0.4289   0.0681   0.0211   0.4751
## 210:    0.4398   1.0138   3.4447   0.4288   0.0674   0.0211   0.4734
## 211:    0.4438   1.0140   3.4459   0.4319   0.0679   0.0210   0.4713
## 212:    0.4469   1.0123   3.4466   0.4305   0.0677   0.0208   0.4713
## 213:    0.4485   1.0098   3.4471   0.4290   0.0681   0.0205   0.4730
## 214:    0.4530   1.0094   3.4477   0.4334   0.0690   0.0203   0.4742
## 215:    0.4545   1.0090   3.4489   0.4332   0.0699   0.0202   0.4744
## 216:    0.4583   1.0073   3.4497   0.4417   0.0700   0.0201   0.4762
## 217:    0.4604   1.0077   3.4503   0.4452   0.0699   0.0201   0.4759
## 218:    0.4626   1.0079   3.4503   0.4496   0.0696   0.0201   0.4763
## 219:    0.4624   1.0075   3.4498   0.4515   0.0693   0.0200   0.4768
## 220:    0.4602   1.0079   3.4497   0.4489   0.0691   0.0200   0.4768
## 221:    0.4581   1.0083   3.4493   0.4453   0.0688   0.0201   0.4768
## 222:    0.4584   1.0087   3.4494   0.4475   0.0686   0.0202   0.4772
## 223:    0.4601   1.0084   3.4499   0.4486   0.0683   0.0204   0.4766
## 224:    0.4629   1.0089   3.4505   0.4514   0.0681   0.0206   0.4759
## 225:    0.4630   1.0076   3.4510   0.4510   0.0679   0.0206   0.4761
## 226:    0.4642   1.0062   3.4513   0.4513   0.0680   0.0207   0.4762
## 227:    0.4646   1.0059   3.4516   0.4495   0.0682   0.0207   0.4758
## 228:    0.4647   1.0068   3.4514   0.4491   0.0680   0.0207   0.4761
## 229:    0.4643   1.0066   3.4512   0.4489   0.0678   0.0208   0.4759
## 230:    0.4635   1.0067   3.4508   0.4473   0.0678   0.0209   0.4760
## 231:    0.4631   1.0070   3.4511   0.4443   0.0675   0.0210   0.4762
## 232:    0.4629   1.0071   3.4513   0.4432   0.0674   0.0209   0.4757
## 233:    0.4623   1.0063   3.4515   0.4448   0.0673   0.0209   0.4762
## 234:    0.4615   1.0065   3.4515   0.4432   0.0672   0.0209   0.4765
## 235:    0.4608   1.0064   3.4511   0.4419   0.0670   0.0210   0.4762
## 236:    0.4606   1.0071   3.4509   0.4405   0.0669   0.0210   0.4761
## 237:    0.4607   1.0067   3.4511   0.4405   0.0669   0.0211   0.4767
## 238:    0.4611   1.0073   3.4510   0.4401   0.0671   0.0211   0.4779
## 239:    0.4608   1.0078   3.4510   0.4394   0.0672   0.0210   0.4780
## 240:    0.4609   1.0079   3.4512   0.4390   0.0674   0.0210   0.4776
## 241:    0.4620   1.0072   3.4514   0.4393   0.0676   0.0210   0.4776
## 242:    0.4624   1.0069   3.4514   0.4384   0.0680   0.0210   0.4779
## 243:    0.4624   1.0072   3.4514   0.4370   0.0684   0.0210   0.4780
## 244:    0.4619   1.0073   3.4516   0.4345   0.0687   0.0209   0.4786
## 245:    0.4618   1.0068   3.4519   0.4321   0.0688   0.0208   0.4791
## 246:    0.4620   1.0065   3.4520   0.4303   0.0690   0.0208   0.4797
## 247:    0.4624   1.0065   3.4523   0.4300   0.0692   0.0209   0.4800
## 248:    0.4626   1.0065   3.4526   0.4290   0.0691   0.0209   0.4797
## 249:    0.4622   1.0067   3.4526   0.4280   0.0691   0.0209   0.4795
## 250:    0.4630   1.0072   3.4529   0.4283   0.0690   0.0209   0.4794
## 251:    0.4640   1.0074   3.4533   0.4293   0.0691   0.0209   0.4790
## 252:    0.4646   1.0076   3.4538   0.4306   0.0690   0.0209   0.4791
## 253:    0.4647   1.0078   3.4540   0.4311   0.0688   0.0209   0.4795
## 254:    0.4644   1.0081   3.4542   0.4316   0.0689   0.0208   0.4795
## 255:    0.4641   1.0085   3.4543   0.4304   0.0690   0.0209   0.4797
## 256:    0.4640   1.0086   3.4542   0.4303   0.0689   0.0209   0.4792
## 257:    0.4636   1.0082   3.4541   0.4300   0.0687   0.0208   0.4790
## 258:    0.4634   1.0079   3.4539   0.4316   0.0688   0.0209   0.4786
## 259:    0.4631   1.0077   3.4538   0.4314   0.0689   0.0209   0.4781
## 260:    0.4628   1.0080   3.4539   0.4310   0.0688   0.0209   0.4780
## 261:    0.4631   1.0080   3.4541   0.4300   0.0688   0.0209   0.4779
## 262:    0.4628   1.0082   3.4541   0.4287   0.0690   0.0209   0.4778
## 263:    0.4626   1.0083   3.4542   0.4280   0.0689   0.0209   0.4778
## 264:    0.4621   1.0087   3.4541   0.4281   0.0689   0.0208   0.4781
## 265:    0.4621   1.0089   3.4540   0.4285   0.0692   0.0208   0.4782
## 266:    0.4620   1.0092   3.4539   0.4300   0.0691   0.0207   0.4782
## 267:    0.4617   1.0096   3.4538   0.4320   0.0692   0.0207   0.4783
## 268:    0.4620   1.0098   3.4536   0.4329   0.0691   0.0207   0.4786
## 269:    0.4622   1.0099   3.4535   0.4326   0.0691   0.0206   0.4788
## 270:    0.4622   1.0103   3.4532   0.4333   0.0692   0.0206   0.4785
## 271:    0.4621   1.0107   3.4530   0.4330   0.0691   0.0205   0.4787
## 272:    0.4623   1.0107   3.4528   0.4326   0.0693   0.0205   0.4790
## 273:    0.4619   1.0111   3.4528   0.4316   0.0695   0.0205   0.4791
## 274:    0.4618   1.0114   3.4529   0.4301   0.0697   0.0204   0.4792
## 275:    0.4618   1.0115   3.4529   0.4293   0.0699   0.0204   0.4789
## 276:    0.4615   1.0116   3.4529   0.4290   0.0700   0.0203   0.4788
## 277:    0.4606   1.0117   3.4529   0.4281   0.0699   0.0203   0.4789
## 278:    0.4603   1.0116   3.4529   0.4280   0.0697   0.0203   0.4791
## 279:    0.4602   1.0114   3.4530   0.4281   0.0695   0.0203   0.4793
## 280:    0.4602   1.0114   3.4532   0.4279   0.0695   0.0203   0.4792
## 281:    0.4604   1.0115   3.4534   0.4283   0.0694   0.0203   0.4792
## 282:    0.4609   1.0118   3.4535   0.4296   0.0695   0.0202   0.4792
## 283:    0.4610   1.0120   3.4536   0.4308   0.0694   0.0202   0.4799
## 284:    0.4605   1.0121   3.4534   0.4321   0.0693   0.0202   0.4800
## 285:    0.4600   1.0124   3.4531   0.4318   0.0692   0.0202   0.4798
## 286:    0.4595   1.0128   3.4529   0.4320   0.0692   0.0201   0.4797
## 287:    0.4589   1.0133   3.4525   0.4321   0.0693   0.0201   0.4796
## 288:    0.4587   1.0134   3.4523   0.4316   0.0694   0.0201   0.4798
## 289:    0.4579   1.0134   3.4521   0.4304   0.0695   0.0201   0.4799
## 290:    0.4577   1.0135   3.4519   0.4304   0.0696   0.0201   0.4800
## 291:    0.4577   1.0140   3.4519   0.4310   0.0697   0.0201   0.4799
## 292:    0.4577   1.0141   3.4517   0.4316   0.0699   0.0201   0.4799
## 293:    0.4575   1.0141   3.4516   0.4319   0.0699   0.0201   0.4802
## 294:    0.4575   1.0141   3.4514   0.4323   0.0699   0.0202   0.4804
## 295:    0.4574   1.0138   3.4514   0.4326   0.0699   0.0202   0.4803
## 296:    0.4572   1.0139   3.4515   0.4318   0.0698   0.0202   0.4805
## 297:    0.4571   1.0140   3.4514   0.4320   0.0698   0.0203   0.4806
## 298:    0.4571   1.0140   3.4514   0.4314   0.0698   0.0203   0.4808
## 299:    0.4573   1.0140   3.4514   0.4317   0.0699   0.0202   0.4809
## 300:    0.4575   1.0140   3.4515   0.4322   0.0699   0.0202   0.4808
## 301:    0.4577   1.0138   3.4514   0.4315   0.0699   0.0201   0.4808
## 302:    0.4579   1.0139   3.4515   0.4309   0.0699   0.0201   0.4806
## 303:    0.4582   1.0138   3.4516   0.4304   0.0699   0.0202   0.4804
## 304:    0.4583   1.0140   3.4516   0.4309   0.0698   0.0202   0.4804
## 305:    0.4584   1.0138   3.4515   0.4304   0.0698   0.0202   0.4805
## 306:    0.4579   1.0139   3.4513   0.4301   0.0698   0.0202   0.4805
## 307:    0.4575   1.0138   3.4512   0.4292   0.0698   0.0202   0.4807
## 308:    0.4571   1.0137   3.4510   0.4291   0.0698   0.0202   0.4809
## 309:    0.4566   1.0135   3.4509   0.4291   0.0698   0.0202   0.4812
## 310:    0.4566   1.0135   3.4507   0.4294   0.0699   0.0202   0.4816
## 311:    0.4567   1.0133   3.4507   0.4296   0.0699   0.0201   0.4816
## 312:    0.4564   1.0133   3.4506   0.4300   0.0701   0.0201   0.4817
## 313:    0.4561   1.0131   3.4504   0.4300   0.0701   0.0200   0.4820
## 314:    0.4556   1.0129   3.4504   0.4296   0.0701   0.0200   0.4821
## 315:    0.4555   1.0129   3.4504   0.4296   0.0701   0.0199   0.4821
## 316:    0.4556   1.0130   3.4503   0.4297   0.0702   0.0199   0.4821
## 317:    0.4556   1.0132   3.4503   0.4290   0.0702   0.0199   0.4821
## 318:    0.4556   1.0134   3.4503   0.4286   0.0702   0.0199   0.4821
## 319:    0.4554   1.0135   3.4503   0.4279   0.0702   0.0199   0.4823
## 320:    0.4551   1.0134   3.4502   0.4278   0.0702   0.0198   0.4823
## 321:    0.4546   1.0136   3.4500   0.4277   0.0701   0.0198   0.4823
## 322:    0.4547   1.0136   3.4499   0.4287   0.0701   0.0198   0.4822
## 323:    0.4546   1.0136   3.4498   0.4291   0.0701   0.0198   0.4820
## 324:    0.4544   1.0138   3.4497   0.4298   0.0701   0.0198   0.4819
## 325:    0.4544   1.0140   3.4496   0.4298   0.0701   0.0198   0.4818
## 326:    0.4542   1.0139   3.4495   0.4298   0.0701   0.0198   0.4817
## 327:    0.4545   1.0141   3.4495   0.4309   0.0701   0.0198   0.4815
## 328:    0.4545   1.0141   3.4494   0.4315   0.0701   0.0198   0.4815
## 329:    0.4547   1.0142   3.4495   0.4318   0.0701   0.0198   0.4814
## 330:    0.4544   1.0142   3.4495   0.4317   0.0701   0.0198   0.4813
## 331:    0.4544   1.0143   3.4495   0.4311   0.0701   0.0198   0.4813
## 332:    0.4545   1.0145   3.4496   0.4310   0.0701   0.0198   0.4814
## 333:    0.4546   1.0145   3.4495   0.4313   0.0702   0.0197   0.4815
## 334:    0.4543   1.0145   3.4494   0.4314   0.0702   0.0197   0.4814
## 335:    0.4543   1.0146   3.4492   0.4318   0.0703   0.0197   0.4813
## 336:    0.4536   1.0149   3.4490   0.4318   0.0704   0.0197   0.4814
## 337:    0.4533   1.0153   3.4488   0.4322   0.0706   0.0197   0.4812
## 338:    0.4533   1.0155   3.4488   0.4323   0.0708   0.0197   0.4811
## 339:    0.4532   1.0157   3.4488   0.4318   0.0708   0.0196   0.4811
## 340:    0.4532   1.0155   3.4488   0.4318   0.0709   0.0196   0.4811
## 341:    0.4535   1.0154   3.4489   0.4317   0.0709   0.0196   0.4811
## 342:    0.4534   1.0153   3.4489   0.4312   0.0709   0.0196   0.4811
## 343:    0.4532   1.0153   3.4489   0.4307   0.0710   0.0196   0.4810
## 344:    0.4532   1.0153   3.4489   0.4306   0.0709   0.0196   0.4810
## 345:    0.4533   1.0153   3.4490   0.4303   0.0708   0.0196   0.4810
## 346:    0.4531   1.0154   3.4489   0.4300   0.0707   0.0196   0.4809
## 347:    0.4529   1.0155   3.4488   0.4300   0.0707   0.0196   0.4809
## 348:    0.4526   1.0156   3.4486   0.4300   0.0706   0.0196   0.4810
## 349:    0.4523   1.0157   3.4485   0.4301   0.0706   0.0196   0.4810
## 350:    0.4520   1.0157   3.4484   0.4301   0.0705   0.0196   0.4809
## 351:    0.4519   1.0157   3.4483   0.4303   0.0704   0.0196   0.4809
## 352:    0.4517   1.0158   3.4482   0.4303   0.0703   0.0196   0.4811
## 353:    0.4519   1.0160   3.4482   0.4305   0.0703   0.0196   0.4811
## 354:    0.4519   1.0160   3.4481   0.4304   0.0703   0.0196   0.4811
## 355:    0.4521   1.0160   3.4481   0.4305   0.0704   0.0196   0.4810
## 356:    0.4520   1.0158   3.4481   0.4298   0.0704   0.0196   0.4811
## 357:    0.4519   1.0159   3.4481   0.4296   0.0704   0.0196   0.4811
## 358:    0.4519   1.0160   3.4482   0.4291   0.0704   0.0195   0.4809
## 359:    0.4517   1.0161   3.4482   0.4288   0.0704   0.0195   0.4808
## 360:    0.4515   1.0160   3.4481   0.4289   0.0704   0.0195   0.4807
## 361:    0.4512   1.0161   3.4481   0.4283   0.0703   0.0195   0.4806
## 362:    0.4511   1.0161   3.4481   0.4281   0.0703   0.0195   0.4804
## 363:    0.4511   1.0160   3.4481   0.4280   0.0702   0.0195   0.4802
## 364:    0.4512   1.0160   3.4481   0.4282   0.0701   0.0195   0.4802
## 365:    0.4512   1.0158   3.4482   0.4281   0.0701   0.0196   0.4802
## 366:    0.4510   1.0158   3.4482   0.4274   0.0700   0.0196   0.4804
## 367:    0.4510   1.0158   3.4482   0.4270   0.0700   0.0196   0.4804
## 368:    0.4511   1.0158   3.4482   0.4270   0.0700   0.0196   0.4803
## 369:    0.4513   1.0158   3.4482   0.4273   0.0700   0.0196   0.4802
## 370:    0.4514   1.0157   3.4483   0.4271   0.0699   0.0196   0.4803
## 371:    0.4513   1.0158   3.4482   0.4269   0.0700   0.0197   0.4802
## 372:    0.4509   1.0161   3.4481   0.4266   0.0700   0.0197   0.4802
## 373:    0.4505   1.0163   3.4479   0.4263   0.0700   0.0197   0.4801
## 374:    0.4502   1.0164   3.4478   0.4260   0.0700   0.0196   0.4800
## 375:    0.4499   1.0164   3.4477   0.4258   0.0700   0.0196   0.4799
## 376:    0.4496   1.0166   3.4477   0.4254   0.0700   0.0196   0.4798
## 377:    0.4494   1.0167   3.4477   0.4251   0.0700   0.0196   0.4796
## 378:    0.4492   1.0167   3.4476   0.4250   0.0700   0.0196   0.4796
## 379:    0.4490   1.0166   3.4475   0.4251   0.0700   0.0196   0.4796
## 380:    0.4488   1.0166   3.4474   0.4250   0.0701   0.0196   0.4796
## 381:    0.4486   1.0166   3.4474   0.4249   0.0701   0.0196   0.4796
## 382:    0.4484   1.0167   3.4474   0.4245   0.0701   0.0195   0.4795
## 383:    0.4484   1.0166   3.4474   0.4244   0.0700   0.0195   0.4794
## 384:    0.4483   1.0165   3.4474   0.4240   0.0700   0.0196   0.4794
## 385:    0.4484   1.0164   3.4474   0.4242   0.0699   0.0196   0.4793
## 386:    0.4486   1.0165   3.4475   0.4243   0.0700   0.0196   0.4792
## 387:    0.4488   1.0166   3.4476   0.4239   0.0699   0.0196   0.4792
## 388:    0.4489   1.0166   3.4477   0.4240   0.0699   0.0196   0.4791
## 389:    0.4488   1.0165   3.4477   0.4239   0.0699   0.0196   0.4791
## 390:    0.4487   1.0166   3.4476   0.4238   0.0700   0.0196   0.4789
## 391:    0.4489   1.0166   3.4476   0.4238   0.0700   0.0196   0.4789
## 392:    0.4489   1.0166   3.4476   0.4239   0.0699   0.0196   0.4790
## 393:    0.4489   1.0166   3.4476   0.4241   0.0699   0.0195   0.4790
## 394:    0.4491   1.0167   3.4475   0.4241   0.0699   0.0195   0.4790
## 395:    0.4492   1.0167   3.4475   0.4236   0.0699   0.0195   0.4791
## 396:    0.4492   1.0168   3.4476   0.4237   0.0698   0.0195   0.4791
## 397:    0.4494   1.0165   3.4477   0.4237   0.0698   0.0195   0.4790
## 398:    0.4498   1.0164   3.4479   0.4237   0.0698   0.0195   0.4790
## 399:    0.4502   1.0162   3.4481   0.4235   0.0699   0.0196   0.4789
## 400:    0.4504   1.0161   3.4482   0.4234   0.0699   0.0196   0.4789
## 401:    0.4505   1.0161   3.4482   0.4231   0.0699   0.0196   0.4791
## 402:    0.4505   1.0161   3.4483   0.4227   0.0699   0.0196   0.4792
## 403:    0.4508   1.0160   3.4483   0.4227   0.0699   0.0196   0.4792
## 404:    0.4509   1.0160   3.4483   0.4227   0.0699   0.0196   0.4791
## 405:    0.4509   1.0160   3.4483   0.4228   0.0699   0.0196   0.4791
## 406:    0.4509   1.0160   3.4483   0.4228   0.0699   0.0196   0.4791
## 407:    0.4509   1.0159   3.4484   0.4229   0.0699   0.0196   0.4790
## 408:    0.4512   1.0160   3.4484   0.4230   0.0700   0.0196   0.4790
## 409:    0.4511   1.0160   3.4484   0.4228   0.0700   0.0196   0.4790
## 410:    0.4509   1.0160   3.4483   0.4226   0.0700   0.0196   0.4790
## 411:    0.4508   1.0160   3.4482   0.4226   0.0700   0.0196   0.4791
## 412:    0.4508   1.0161   3.4482   0.4220   0.0700   0.0196   0.4792
## 413:    0.4505   1.0162   3.4482   0.4214   0.0699   0.0196   0.4793
## 414:    0.4503   1.0163   3.4482   0.4217   0.0699   0.0196   0.4792
## 415:    0.4504   1.0163   3.4481   0.4217   0.0699   0.0196   0.4791
## 416:    0.4503   1.0164   3.4481   0.4216   0.0698   0.0196   0.4792
## 417:    0.4503   1.0164   3.4481   0.4216   0.0698   0.0196   0.4791
## 418:    0.4503   1.0164   3.4481   0.4215   0.0699   0.0196   0.4790
## 419:    0.4504   1.0164   3.4481   0.4217   0.0699   0.0197   0.4789
## 420:    0.4506   1.0165   3.4482   0.4216   0.0700   0.0196   0.4788
## 421:    0.4505   1.0165   3.4483   0.4214   0.0700   0.0196   0.4788
## 422:    0.4507   1.0163   3.4483   0.4214   0.0700   0.0196   0.4787
## 423:    0.4509   1.0163   3.4484   0.4213   0.0701   0.0196   0.4787
## 424:    0.4507   1.0162   3.4483   0.4214   0.0701   0.0196   0.4786
## 425:    0.4507   1.0163   3.4482   0.4216   0.0701   0.0196   0.4785
## 426:    0.4507   1.0164   3.4482   0.4217   0.0701   0.0196   0.4784
## 427:    0.4506   1.0165   3.4482   0.4218   0.0701   0.0196   0.4784
## 428:    0.4507   1.0165   3.4482   0.4215   0.0701   0.0196   0.4784
## 429:    0.4508   1.0165   3.4483   0.4213   0.0700   0.0196   0.4785
## 430:    0.4507   1.0165   3.4483   0.4210   0.0701   0.0196   0.4786
## 431:    0.4505   1.0165   3.4483   0.4208   0.0701   0.0196   0.4785
## 432:    0.4504   1.0166   3.4483   0.4207   0.0701   0.0196   0.4784
## 433:    0.4503   1.0167   3.4483   0.4207   0.0702   0.0196   0.4784
## 434:    0.4503   1.0166   3.4483   0.4206   0.0702   0.0196   0.4784
## 435:    0.4502   1.0166   3.4483   0.4203   0.0702   0.0196   0.4783
## 436:    0.4502   1.0166   3.4484   0.4201   0.0702   0.0196   0.4784
## 437:    0.4503   1.0166   3.4484   0.4202   0.0703   0.0196   0.4784
## 438:    0.4501   1.0167   3.4483   0.4200   0.0703   0.0195   0.4784
## 439:    0.4501   1.0168   3.4483   0.4200   0.0703   0.0195   0.4784
## 440:    0.4502   1.0168   3.4484   0.4198   0.0703   0.0195   0.4784
## 441:    0.4504   1.0168   3.4484   0.4199   0.0703   0.0195   0.4783
## 442:    0.4504   1.0169   3.4485   0.4200   0.0702   0.0195   0.4783
## 443:    0.4506   1.0169   3.4485   0.4202   0.0702   0.0195   0.4782
## 444:    0.4505   1.0170   3.4484   0.4201   0.0703   0.0195   0.4783
## 445:    0.4505   1.0170   3.4483   0.4205   0.0703   0.0194   0.4783
## 446:    0.4504   1.0171   3.4483   0.4207   0.0704   0.0194   0.4784
## 447:    0.4506   1.0171   3.4483   0.4209   0.0704   0.0194   0.4784
## 448:    0.4507   1.0171   3.4484   0.4207   0.0704   0.0194   0.4783
## 449:    0.4509   1.0171   3.4485   0.4203   0.0704   0.0194   0.4783
## 450:    0.4510   1.0171   3.4486   0.4201   0.0704   0.0194   0.4783
## 451:    0.4512   1.0170   3.4487   0.4201   0.0703   0.0194   0.4783
## 452:    0.4515   1.0170   3.4488   0.4200   0.0703   0.0194   0.4783
## 453:    0.4515   1.0169   3.4488   0.4197   0.0703   0.0194   0.4782
## 454:    0.4516   1.0170   3.4488   0.4194   0.0703   0.0194   0.4781
## 455:    0.4517   1.0170   3.4489   0.4194   0.0702   0.0194   0.4780
## 456:    0.4518   1.0169   3.4488   0.4195   0.0702   0.0194   0.4780
## 457:    0.4518   1.0169   3.4489   0.4195   0.0702   0.0194   0.4780
## 458:    0.4518   1.0169   3.4489   0.4195   0.0701   0.0194   0.4779
## 459:    0.4515   1.0170   3.4488   0.4194   0.0701   0.0194   0.4779
## 460:    0.4513   1.0171   3.4488   0.4192   0.0700   0.0194   0.4779
## 461:    0.4511   1.0172   3.4488   0.4190   0.0700   0.0194   0.4780
## 462:    0.4510   1.0173   3.4488   0.4187   0.0700   0.0194   0.4780
## 463:    0.4510   1.0173   3.4488   0.4184   0.0700   0.0194   0.4781
## 464:    0.4510   1.0174   3.4487   0.4182   0.0700   0.0194   0.4780
## 465:    0.4510   1.0173   3.4487   0.4181   0.0700   0.0194   0.4780
## 466:    0.4509   1.0173   3.4487   0.4177   0.0700   0.0194   0.4781
## 467:    0.4507   1.0172   3.4488   0.4173   0.0700   0.0194   0.4781
## 468:    0.4508   1.0172   3.4488   0.4172   0.0701   0.0194   0.4782
## 469:    0.4508   1.0174   3.4488   0.4174   0.0701   0.0194   0.4783
## 470:    0.4507   1.0174   3.4488   0.4175   0.0702   0.0193   0.4783
## 471:    0.4507   1.0174   3.4487   0.4174   0.0702   0.0193   0.4784
## 472:    0.4507   1.0174   3.4488   0.4173   0.0702   0.0193   0.4784
## 473:    0.4506   1.0174   3.4488   0.4171   0.0702   0.0193   0.4784
## 474:    0.4507   1.0174   3.4488   0.4170   0.0702   0.0193   0.4785
## 475:    0.4507   1.0175   3.4488   0.4169   0.0702   0.0193   0.4785
## 476:    0.4507   1.0175   3.4488   0.4171   0.0702   0.0193   0.4785
## 477:    0.4506   1.0175   3.4488   0.4170   0.0702   0.0193   0.4784
## 478:    0.4505   1.0175   3.4488   0.4169   0.0702   0.0193   0.4784
## 479:    0.4507   1.0174   3.4489   0.4170   0.0703   0.0193   0.4786
## 480:    0.4506   1.0174   3.4489   0.4167   0.0704   0.0193   0.4787
## 481:    0.4506   1.0175   3.4489   0.4164   0.0704   0.0193   0.4788
## 482:    0.4506   1.0175   3.4489   0.4164   0.0703   0.0193   0.4788
## 483:    0.4506   1.0174   3.4489   0.4165   0.0703   0.0193   0.4788
## 484:    0.4506   1.0173   3.4489   0.4166   0.0703   0.0193   0.4788
## 485:    0.4507   1.0174   3.4489   0.4168   0.0703   0.0193   0.4788
## 486:    0.4507   1.0174   3.4489   0.4166   0.0703   0.0193   0.4788
## 487:    0.4509   1.0174   3.4490   0.4166   0.0703   0.0193   0.4787
## 488:    0.4509   1.0173   3.4490   0.4165   0.0703   0.0193   0.4787
## 489:    0.4511   1.0173   3.4490   0.4166   0.0703   0.0193   0.4787
## 490:    0.4513   1.0173   3.4491   0.4167   0.0703   0.0193   0.4787
## 491:    0.4513   1.0173   3.4491   0.4166   0.0703   0.0193   0.4787
## 492:    0.4514   1.0173   3.4492   0.4164   0.0703   0.0193   0.4787
## 493:    0.4513   1.0173   3.4492   0.4163   0.0703   0.0193   0.4787
## 494:    0.4513   1.0173   3.4491   0.4161   0.0703   0.0193   0.4787
## 495:    0.4513   1.0173   3.4491   0.4160   0.0703   0.0193   0.4786
## 496:    0.4514   1.0173   3.4491   0.4160   0.0703   0.0193   0.4786
## 497:    0.4513   1.0173   3.4491   0.4163   0.0702   0.0193   0.4786
## 498:    0.4513   1.0173   3.4490   0.4163   0.0702   0.0193   0.4785
## 499:    0.4513   1.0174   3.4490   0.4165   0.0702   0.0193   0.4784
## 500:    0.4513   1.0173   3.4489   0.4164   0.0702   0.0193   0.4783</code></pre>
<pre><code>## Calculating covariance matrix</code></pre>
<pre><code>## [====|====|====|====|====|====|====|====|====|====</code></pre>
<pre><code>## Calculating residuals/tables
## done.
## Calculating -2LL by Gaussian quadrature (nnodes=3,nsd=1.6)</code></pre>
<pre><code>## [====|====|====|====|====|====|====|====|====|====</code></pre>
<p>Options to the estimation routines can be specified using nlmeControl for nlme estimation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit4 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/nlmixr.html">nlmixr</a></span>(one.compartment, theo_sd,<span class="dt">est=</span><span class="st">"nlme"</span>,<span class="dt">control =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/nlme/topics/nlmeControl">nlmeControl</a></span>(<span class="dt">pnlsTol =</span> .<span class="dv">5</span>))</code></pre></div>
<pre><code>## 
## **Iteration 1
## LME step: Loglik: -200.3342, nlminb iterations: 1
## reStruct  parameters:
##      ID1      ID2      ID3 
## 1.271715 1.182325 2.187380 
##  Beginning PNLS step: ..  completed fit_nlme() step.
## PNLS step: RSS =  65.45651 
##  fixed effects: 0.4707859  1.007357  3.470158  
##  iterations: 6 
## Convergence crit. (must all become &lt;= tolerance = 1e-05):
##       fixed    reStruct 
##  0.04415156 14.87446795 
## 
## **Iteration 2
## LME step: Loglik: -181.1668, nlminb iterations: 1
## reStruct  parameters:
##        ID1        ID2        ID3 
## 0.08011074 1.02843991 1.44894141 
##  Beginning PNLS step: ..  completed fit_nlme() step.
## PNLS step: RSS =  65.45651 
##  fixed effects: 0.4707859  1.007357  3.470158  
##  iterations: 1 
## Convergence crit. (must all become &lt;= tolerance = 1e-05):
##        fixed     reStruct 
## 0.000000e+00 1.111923e-06</code></pre>
<pre><code>## Calculating residuals/tables</code></pre>
<pre><code>## done.</code></pre>
<pre><code>## Warning in (function (uif, data, est = NULL, control = list(), ...,
## sum.prod = FALSE, : Initial condition for additive error ignored with nlme</code></pre>
<p>where options are specified in the <code>nlme</code> documentation. Options for saem can be specified using <code>saemControl</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit5 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/nlmixr.html">nlmixr</a></span>(one.compartment,theo_sd,<span class="dt">est=</span><span class="st">"saem"</span>,<span class="dt">control=</span><span class="kw"><a href="../reference/saemControl.html">saemControl</a></span>(<span class="dt">n.burn=</span><span class="dv">250</span>,<span class="dt">n.em=</span><span class="dv">350</span>,<span class="dt">print=</span><span class="dv">50</span>))</code></pre></div>
<pre><code>## Compiling RxODE equations...done.</code></pre>
<pre><code>## 1:    0.2288   0.9677   3.4737   0.5700   0.2850   0.0950   4.5245
## 50:    0.4538   0.9948   3.4407   0.4076   0.0767   0.0227   0.5089
## 100:    0.4279   1.0081   3.4471   0.4205   0.0648   0.0213   0.4570
## 150:    0.4642   0.9971   3.4466   0.3686   0.0714   0.0172   0.4834
## 200:    0.4081   1.0160   3.4397   0.3959   0.0803   0.0168   0.5006
## 250:    0.4900   1.0196   3.4700   0.4459   0.0696   0.0229   0.4993
## 300:    0.4547   1.0231   3.4500   0.4374   0.0702   0.0189   0.4824
## 350:    0.4414   1.0226   3.4436   0.4302   0.0716   0.0183   0.4850
## 400:    0.4437   1.0206   3.4453   0.4217   0.0711   0.0178   0.4834
## 450:    0.4458   1.0209   3.4463   0.4159   0.0720   0.0179   0.4818
## 500:    0.4473   1.0211   3.4468   0.4141   0.0717   0.0178   0.4806
## 550:    0.4489   1.0200   3.4472   0.4125   0.0721   0.0176   0.4808
## 600:    0.4509   1.0185   3.4483   0.4099   0.0719   0.0178   0.4810</code></pre>
<pre><code>## Calculating covariance matrix</code></pre>
<pre><code>## [====|====|====|====|====|====|====|====|====|====</code></pre>
<pre><code>## Calculating residuals/tables
## done.
## Calculating -2LL by Gaussian quadrature (nnodes=3,nsd=1.6)</code></pre>
<pre><code>## [====|====|====|====|====|====|====|====|====|====</code></pre>
<p>this example specifies 250 burn-in iterations, 350 em iterations and a print progress every 50 runs.</p>
</div>
<div id="model-syntax-for-solved-pk-systems" class="section level2">
<h2 class="hasAnchor">
<a href="#model-syntax-for-solved-pk-systems" class="anchor"></a>Model Syntax for solved PK systems</h2>
<p>Solved PK systems are also currently supported by nlmixr with the ‘linCmt()’ pseudo-function. An annotated example of a solved system is below:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f &lt;-<span class="st"> </span><span class="cf">function</span>(){
    <span class="kw"><a href="../reference/ini.html">ini</a></span>({
        lCl &lt;-<span class="st"> </span><span class="fl">1.6</span>      <span class="co">#log Cl (L/hr)</span>
        lVc &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Log">log</a></span>(<span class="dv">90</span>)  <span class="co">#log Vc (L)</span>
        lKA &lt;-<span class="st"> </span><span class="fl">0.1</span>      <span class="co">#log Ka (1/hr)</span>
        prop.err &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="dv">0</span>, <span class="fl">0.2</span>, <span class="dv">1</span>)
        eta.Cl <span class="op">~</span><span class="st"> </span><span class="fl">0.1</span>   <span class="co"># BSV Cl</span>
        eta.Vc <span class="op">~</span><span class="st"> </span><span class="fl">0.1</span>   <span class="co"># BSV Vc</span>
        eta.KA <span class="op">~</span><span class="st"> </span><span class="fl">0.1</span>   <span class="co"># BSV Ka</span>
    })
    <span class="kw"><a href="../reference/model.html">model</a></span>({
        Cl &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Log">exp</a></span>(lCl <span class="op">+</span><span class="st"> </span>eta.Cl)
        Vc =<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Log">exp</a></span>(lVc <span class="op">+</span><span class="st"> </span>eta.Vc)
        KA &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Log">exp</a></span>(lKA <span class="op">+</span><span class="st"> </span>eta.KA)
        ## Instead of specifying the ODEs, you can use
        ## the linCmt() function to use the solved system.
        ##
        ## This function determines the type of PK solved system
        ## to use by the parameters that are defined.  In this case
        ## it knows that this is a one-compartment model with first-order
        ## absorption.
        <span class="kw">linCmt</span>() <span class="op">~</span><span class="st"> </span><span class="kw">prop</span>(prop.err)
    })
}</code></pre></div>
<p>A few things to keep in mind: * Currently the solved systems support either oral dosing, IV dosing or IV infusion dosing and does not allow mixing the dosing types. * While RxODE allows mixing of solved systems and ODEs, this has not been implemented in nlmixr yet. * The solved systems implemented are the one, two and three compartment models with or without first-order absorption. Each of the models support a lag time with a tlag parameter. * In general the linear compartment model figures out the model by the parameter names. nlmixr currently knows about numbered volumes, <code>Vc</code>/<code>Vp</code>, Clearances in terms of both <code>Cl</code> and <code>Q</code>/<code>CLD</code>. Additionally nlmixr knows about elimination micro-constants (ie <code>K12</code>). Mixing of these parameters for these models is currently not supported.</p>
</div>
<div id="checking-model-syntax" class="section level2">
<h2 class="hasAnchor">
<a href="#checking-model-syntax" class="anchor"></a>Checking model syntax</h2>
<p>After specifying the model syntax you can check that nlmixr is interpreting it correctly by using the nlmixr function on it. Using the above function we can get:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/nlmixr.html">nlmixr</a></span>(f)</code></pre></div>
<pre><code>## ▂▂ RxODE-based 1-compartment model with first-order absorption ▂▂▂▂▂▂▂▂▂▂▂▂ 
## ── Initialization: ──────────────────────────────────────────────────────── 
## Fixed Effects ($theta): 
##     lCl     lVc     lKA 
## 1.60000 4.49981 0.10000 
## 
## Omega ($omega): 
##        eta.Cl eta.Vc eta.KA
## eta.Cl    0.1    0.0    0.0
## eta.Vc    0.0    0.1    0.0
## eta.KA    0.0    0.0    0.1
## ── μ-referencing ($muRefTable): ─────────────────────────────────────────── 
## ┌─────────┬─────────┐
## │ theta   │ eta     │
## ├─────────┼─────────┤
## │ lCl     │ eta.Cl  │
## ├─────────┼─────────┤
## │ lVc     │ eta.Vc  │
## ├─────────┼─────────┤
## │ lKA     │ eta.KA  │
## └─────────┴─────────┘
## ── Model: ───────────────────────────────────────────────────────────────── 
##         Cl &lt;- exp(lCl + eta.Cl)
##         Vc = exp(lVc + eta.Vc)
##         KA &lt;- exp(lKA + eta.KA)
##         ## Instead of specifying the ODEs, you can use
##         ## the linCmt() function to use the solved system.
##         ##
##         ## This function determines the type of PK solved system
##         ## to use by the parameters that are defined.  In this case
##         ## it knows that this is a one-compartment model with first-order
##         ## absorption.
##         linCmt() ~ prop(prop.err) 
## ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</code></pre>
<p>In general this gives you information about the model (what type of solved system/RxODE), initial estimates as well as the code for the model block.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li>
<a href="#running-pk-models-with-nlmixr">Running PK models with nlmixr</a><ul class="nav nav-pills nav-stacked">
<li><a href="#xpose">xpose</a></li>
      </ul>
</li>
      <li>
<a href="#the-ui">The UI</a><ul class="nav nav-pills nav-stacked">
<li><a href="#overall-model-structure">Overall model structure</a></li>
      <li><a href="#running-models">Running models</a></li>
      <li><a href="#model-syntax-for-solved-pk-systems">Model Syntax for solved PK systems</a></li>
      <li><a href="#checking-model-syntax">Checking model syntax</a></li>
      </ul>
</li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Matthew Fidler, Yuan Xiong, Rik Schoemaker, Justin Wilkins, Mirjam Trame, Richard Hooijmaijers, Teun Post, Wenping Wang.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.3.0.</p>
</div>
      </footer>
</div>

  

  </body>
</html>
